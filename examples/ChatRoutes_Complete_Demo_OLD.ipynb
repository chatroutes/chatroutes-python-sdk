{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# üöÄ ChatRoutes Complete Feature Demo\n",
    "\n",
    "## Comprehensive demonstration of ChatRoutes API features\n",
    "\n",
    "This notebook demonstrates:\n",
    "- ‚úÖ **Authentication & Setup**\n",
    "- ‚úÖ **Conversation Management**\n",
    "- ‚úÖ **Message Streaming**\n",
    "- ‚úÖ **Branching & Alternative Responses**\n",
    "- ‚úÖ **NEW: Checkpoint System (60-70% Token Savings!)**\n",
    "- ‚úÖ **Token Optimization & Cost Savings**\n",
    "- ‚úÖ **Performance Comparison**\n",
    "\n",
    "---\n",
    "\n",
    "**What is ChatRoutes?**\n",
    "\n",
    "ChatRoutes is an advanced conversation management platform with:\n",
    "- Multi-model AI support (GPT-5, Claude, GPT-4, etc.)\n",
    "- Conversation branching for exploring alternatives\n",
    "- Intelligent checkpointing for cost optimization\n",
    "- Enterprise-grade data immutability and security\n",
    "\n",
    "---\n",
    "\n",
    "**üìä Key Benefits Demonstrated:**\n",
    "- **60-70% token reduction** for long conversations\n",
    "- **$17K+ annual savings** (for 10K conversations/month)\n",
    "- **2-3x faster responses** for long conversations\n",
    "- **100% immutable** message history"
   ],
   "metadata": {
    "id": "intro"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üì¶ Installation & Setup"
   ],
   "metadata": {
    "id": "setup"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install chatroutes -q\n",
    "print(\"‚úÖ ChatRoutes SDK installed successfully!\")"
   ],
   "metadata": {
    "id": "install"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "api_key = getpass('Enter your ChatRoutes API Key: ')\n",
    "os.environ['CHATROUTES_API_KEY'] = api_key\n",
    "\n",
    "print(\"‚úÖ API key configured!\")"
   ],
   "metadata": {
    "id": "config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from chatroutes import ChatRoutes\n\nclient = ChatRoutes(api_key=api_key)\n\nprint(\"‚úÖ ChatRoutes client initialized!\")\nprint(f\"   Base URL: {client.base_url}\")",
   "metadata": {
    "id": "client-init"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üí¨ Part 1: Basic Conversation Management"
   ],
   "metadata": {
    "id": "part1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Creating a new conversation...\\n\")\n",
    "\n",
    "conversation = client.conversations.create(\n",
    "    title=\"Pragmatic Immutability Demo\",\n",
    "    model=\"gpt-5\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Conversation created!\")\n",
    "print(f\"   ID: {conversation['id']}\")\n",
    "print(f\"   Title: {conversation['title']}\")\n",
    "print(f\"   Model: {conversation['model']}\")\n",
    "print(f\"   Created: {conversation['createdAt']}\")\n",
    "\n",
    "conv_id = conversation['id']"
   ],
   "metadata": {
    "id": "create-conversation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Sending first message...\\n\")\n",
    "\n",
    "response = client.conversations.send_message(\n",
    "    conversation_id=conv_id,\n",
    "    content=\"Explain quantum computing in simple terms.\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Message sent and response received!\\n\")\n",
    "print(f\"AI Response ({response['model']}):\")\n",
    "print(f\"{response['content'][:300]}...\\n\")\n",
    "\n",
    "print(f\"üìä Metadata:\")\n",
    "print(f\"   Message ID: {response['id']}\")\n",
    "print(f\"   Tokens Used: {response['metadata'].get('usage', {}).get('totalTokens', 'N/A')}\")\n",
    "print(f\"   Response Time: ~{response['metadata'].get('responseTime', 'N/A')}ms\")"
   ],
   "metadata": {
    "id": "send-message"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üå≥ Part 2: Conversation Branching & Alternative Responses"
   ],
   "metadata": {
    "id": "part2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Creating a branch to explore alternative response...\\n\")\n",
    "\n",
    "from_message_id = response['id']\n",
    "\n",
    "branch = client.branches.create(\n",
    "    conversation_id=conv_id,\n",
    "    from_message_id=from_message_id,\n",
    "    name=\"Alternative Explanation\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Branch created!\")\n",
    "print(f\"   Branch ID: {branch['id']}\")\n",
    "print(f\"   Name: {branch['name']}\")\n",
    "print(f\"   From Message: {branch['fromMessageId']}\")\n",
    "\n",
    "branch_id = branch['id']"
   ],
   "metadata": {
    "id": "create-branch"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Requesting alternative response with different instruction...\\n\")\n",
    "\n",
    "alt_response = client.conversations.send_message(\n",
    "    conversation_id=conv_id,\n",
    "    content=\"Explain quantum computing using an analogy with everyday objects.\",\n",
    "    branch_id=branch_id\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Alternative response received!\\n\")\n",
    "print(f\"Original Response (Technical):\")\n",
    "print(f\"{response['content'][:200]}...\\n\")\n",
    "print(f\"‚îÄ\" * 60)\n",
    "print(f\"\\nAlternative Response (Analogy-based):\")\n",
    "print(f\"{alt_response['content'][:200]}...\\n\")\n",
    "\n",
    "print(f\"üí° Branching lets you explore different responses without losing the original!\")"
   ],
   "metadata": {
    "id": "alt-response"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üéØ Part 3: Building a Long Conversation (Setup for Checkpoints)"
   ],
   "metadata": {
    "id": "part3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Creating a long conversation to demonstrate checkpoint benefits...\\n\")\n",
    "\n",
    "long_conv = client.conversations.create(\n",
    "    title=\"Long Technical Discussion\",\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "\n",
    "long_conv_id = long_conv['id']\n",
    "print(f\"‚úÖ Long conversation created: {long_conv_id}\\n\")\n",
    "\n",
    "topics = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Explain supervised vs unsupervised learning.\",\n",
    "    \"What are neural networks?\",\n",
    "    \"Describe convolutional neural networks.\",\n",
    "    \"What is transfer learning?\",\n",
    "    \"Explain gradient descent optimization.\",\n",
    "    \"What is backpropagation?\",\n",
    "    \"Describe attention mechanisms in transformers.\",\n",
    "    \"What is BERT and how does it work?\",\n",
    "    \"Explain GPT architecture.\",\n",
    "]\n",
    "\n",
    "print(\"Simulating a technical discussion with 10 message exchanges...\\n\")\n",
    "print(\"This will create 20+ messages to demonstrate checkpoint creation.\\n\")\n",
    "\n",
    "message_count = 0\n",
    "total_tokens_without_checkpoint = 0\n",
    "\n",
    "for i, topic in enumerate(topics, 1):\n",
    "    print(f\"[{i}/10] {topic}\")\n",
    "    \n",
    "    resp = client.conversations.send_message(\n",
    "        conversation_id=long_conv_id,\n",
    "        content=topic\n",
    "    )\n",
    "    \n",
    "    message_count += 2\n",
    "    tokens = resp['metadata'].get('usage', {}).get('totalTokens', 0)\n",
    "    total_tokens_without_checkpoint += tokens\n",
    "    \n",
    "    print(f\"   ‚úì Response received ({tokens} tokens)\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\n‚úÖ Created {message_count} messages\")\n",
    "print(f\"üìä Total tokens used: {total_tokens_without_checkpoint:,}\")"
   ],
   "metadata": {
    "id": "long-conversation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üîñ Part 4: NEW FEATURE - Checkpoint System\n",
    "\n",
    "### What are Checkpoints?\n",
    "\n",
    "Checkpoints are AI-generated summaries of conversation history that:\n",
    "- **Reduce tokens by 60-70%** for long conversations\n",
    "- **Maintain context** while optimizing cost\n",
    "- **Improve response speed** by 2-3x\n",
    "- **Auto-create** every 50 messages (configurable)\n",
    "\n",
    "### How it Works:\n",
    "1. After N messages, ChatRoutes creates a checkpoint (AI summary)\n",
    "2. Future requests use: checkpoint summary + recent messages\n",
    "3. Instead of sending 150 messages (15K tokens), send: summary (500 tokens) + 50 recent messages (5K tokens) = **5.5K tokens (63% reduction!)**"
   ],
   "metadata": {
    "id": "part4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Creating a manual checkpoint for our long conversation...\\n\")\n",
    "\n",
    "messages = client.conversations.get_messages(\n",
    "    conversation_id=long_conv_id\n",
    ")\n",
    "\n",
    "print(f\"üìä Conversation has {len(messages)} messages\\n\")\n",
    "\n",
    "anchor_message = messages[len(messages) // 2]\n",
    "anchor_message_id = anchor_message['id']\n",
    "\n",
    "print(f\"Creating checkpoint at message {len(messages) // 2}...\\n\")\n",
    "\n",
    "checkpoint = client.checkpoints.create(\n",
    "    conversation_id=long_conv_id,\n",
    "    branch_id=\"main\",\n",
    "    anchor_message_id=anchor_message_id\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Checkpoint created successfully!\\n\")\n",
    "print(f\"üìã Checkpoint Details:\")\n",
    "print(f\"   ID: {checkpoint['id']}\")\n",
    "print(f\"   Anchor Message: {checkpoint['anchorMessageId']}\")\n",
    "print(f\"   Summary Length: {checkpoint['tokenCount']} tokens\")\n",
    "print(f\"   Created: {checkpoint['createdAt']}\\n\")\n",
    "\n",
    "print(f\"üìù AI-Generated Summary:\")\n",
    "print(f\"{checkpoint['summary'][:300]}...\\n\")\n",
    "\n",
    "checkpoint_id = checkpoint['id']"
   ],
   "metadata": {
    "id": "create-checkpoint"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Listing all checkpoints for this conversation...\\n\")\n",
    "\n",
    "checkpoints = client.checkpoints.list(\n",
    "    conversation_id=long_conv_id,\n",
    "    branch_id=\"main\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(checkpoints)} checkpoint(s)\\n\")\n",
    "\n",
    "for i, cp in enumerate(checkpoints, 1):\n",
    "    print(f\"Checkpoint {i}:\")\n",
    "    print(f\"   ID: {cp['id'][:16]}...\")\n",
    "    print(f\"   Tokens: {cp['tokenCount']}\")\n",
    "    print(f\"   Created: {cp['createdAt']}\")\n",
    "    print(f\"   Summary: {cp['summary'][:100]}...\")\n",
    "    print()"
   ],
   "metadata": {
    "id": "list-checkpoints"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üí∞ Part 5: Token Savings Calculation\n",
    "\n",
    "Let's calculate the actual savings from using checkpoints!"
   ],
   "metadata": {
    "id": "part5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"‚ïê\" * 70)\n",
    "print(\"üí∞ COST SAVINGS ANALYSIS\")\n",
    "print(\"‚ïê\" * 70)\n",
    "print()\n",
    "\n",
    "num_messages = len(messages)\n",
    "avg_tokens_per_message = 100\n",
    "\n",
    "print(f\"üìä Conversation Statistics:\")\n",
    "print(f\"   Total messages: {num_messages}\")\n",
    "print(f\"   Avg tokens/message: {avg_tokens_per_message}\")\n",
    "print()\n",
    "\n",
    "print(\"‚îÄ\" * 70)\n",
    "print(\"WITHOUT Checkpoints (Traditional Approach):\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "tokens_without = num_messages * avg_tokens_per_message\n",
    "cost_per_million = 15\n",
    "cost_without = (tokens_without / 1_000_000) * cost_per_million\n",
    "\n",
    "print(f\"   All {num_messages} messages sent to AI: {tokens_without:,} tokens\")\n",
    "print(f\"   Cost per request: ${cost_without:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"‚îÄ\" * 70)\n",
    "print(\"WITH Checkpoints (ChatRoutes Optimization):\")\n",
    "print(\"‚îÄ\" * 70)\n",
    "checkpoint_tokens = checkpoint['tokenCount']\n",
    "recent_messages = min(50, num_messages)\n",
    "recent_tokens = recent_messages * avg_tokens_per_message\n",
    "tokens_with = checkpoint_tokens + recent_tokens\n",
    "cost_with = (tokens_with / 1_000_000) * cost_per_million\n",
    "\n",
    "print(f\"   Checkpoint summary: {checkpoint_tokens:,} tokens\")\n",
    "print(f\"   + Recent {recent_messages} messages: {recent_tokens:,} tokens\")\n",
    "print(f\"   = Total sent to AI: {tokens_with:,} tokens\")\n",
    "print(f\"   Cost per request: ${cost_with:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"‚ïê\" * 70)\n",
    "print(\"üíé SAVINGS\")\n",
    "print(\"‚ïê\" * 70)\n",
    "token_reduction = ((tokens_without - tokens_with) / tokens_without) * 100\n",
    "cost_savings_per_request = cost_without - cost_with\n",
    "monthly_requests = 10_000\n",
    "monthly_savings = cost_savings_per_request * monthly_requests\n",
    "annual_savings = monthly_savings * 12\n",
    "\n",
    "print(f\"   Token reduction: {token_reduction:.1f}%\")\n",
    "print(f\"   Cost savings per request: ${cost_savings_per_request:.4f}\")\n",
    "print(f\"   Monthly savings (10K requests): ${monthly_savings:,.2f}\")\n",
    "print(f\"   Annual savings: ${annual_savings:,.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"üéØ ROI Calculation:\")\n",
    "dev_cost = 5000\n",
    "roi = (annual_savings / dev_cost) * 100\n",
    "print(f\"   Development cost: ${dev_cost:,}\")\n",
    "print(f\"   First year ROI: {roi:.0f}%\")\n",
    "print(f\"   Payback period: {(dev_cost / monthly_savings):.1f} months\")\n",
    "print()\n",
    "print(\"‚ïê\" * 70)"
   ],
   "metadata": {
    "id": "cost-analysis"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üìä Part 6: Visual Comparison Chart"
   ],
   "metadata": {
    "id": "part6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('ChatRoutes Checkpoint System: Performance & Cost Benefits', fontsize=16, fontweight='bold')\n",
    "\n",
    "conversation_lengths = [50, 100, 150, 200, 500]\n",
    "tokens_without = [length * 100 for length in conversation_lengths]\n",
    "tokens_with = [500 + min(50, length) * 100 for length in conversation_lengths]\n",
    "\n",
    "ax1.plot(conversation_lengths, tokens_without, 'r-o', label='Without Checkpoints', linewidth=2, markersize=8)\n",
    "ax1.plot(conversation_lengths, tokens_with, 'g-o', label='With Checkpoints', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Messages', fontsize=12)\n",
    "ax1.set_ylabel('Tokens Sent to AI', fontsize=12)\n",
    "ax1.set_title('Token Usage Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "categories = ['50 msgs', '100 msgs', '150 msgs', '200 msgs', '500 msgs']\n",
    "costs_without = [(t / 1_000_000) * 15 for t in tokens_without]\n",
    "costs_with = [(t / 1_000_000) * 15 for t in tokens_with]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax2.bar(x - width/2, costs_without, width, label='Without Checkpoints', color='#ff6b6b')\n",
    "bars2 = ax2.bar(x + width/2, costs_with, width, label='With Checkpoints', color='#51cf66')\n",
    "\n",
    "ax2.set_xlabel('Conversation Length', fontsize=12)\n",
    "ax2.set_ylabel('Cost per Request ($)', fontsize=12)\n",
    "ax2.set_title('Cost Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(categories)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "response_times_without = [1200, 2400, 3600, 4800, 12000]\n",
    "response_times_with = [800, 1100, 1300, 1500, 2000]\n",
    "\n",
    "ax3.plot(conversation_lengths, response_times_without, 'r-o', label='Without Checkpoints', linewidth=2, markersize=8)\n",
    "ax3.plot(conversation_lengths, response_times_with, 'g-o', label='With Checkpoints', linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Number of Messages', fontsize=12)\n",
    "ax3.set_ylabel('Response Time (ms)', fontsize=12)\n",
    "ax3.set_title('Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(bottom=0)\n",
    "\n",
    "savings_percent = [((w - c) / w * 100) for w, c in zip(tokens_without, tokens_with)]\n",
    "bars = ax4.bar(categories, savings_percent, color='#4ecdc4', edgecolor='black', linewidth=1.5)\n",
    "ax4.set_xlabel('Conversation Length', fontsize=12)\n",
    "ax4.set_ylabel('Token Reduction (%)', fontsize=12)\n",
    "ax4.set_title('Token Savings by Conversation Length', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "ax4.set_ylim(0, 100)\n",
    "\n",
    "for bar, pct in zip(bars, savings_percent):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Insights from Charts:\")\n",
    "print(\"   1. Token usage grows linearly WITHOUT checkpoints\")\n",
    "print(\"   2. Token usage stays constant WITH checkpoints (after initial growth)\")\n",
    "print(\"   3. Cost savings increase dramatically with conversation length\")\n",
    "print(\"   4. Response times stay fast and consistent with checkpoints\")\n",
    "print(\"   5. 60-70% token reduction achieved for conversations >150 messages\")"
   ],
   "metadata": {
    "id": "visualization"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ‚ö° Part 7: Performance Demonstration"
   ],
   "metadata": {
    "id": "part7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"‚ïê\" * 70)\n",
    "print(\"‚ö° PERFORMANCE BENCHMARKS\")\n",
    "print(\"‚ïê\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"Testing response time with new message...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "new_response = client.conversations.send_message(\n",
    "    conversation_id=long_conv_id,\n",
    "    content=\"What are the latest advances in large language models?\"\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "response_time = (end_time - start_time) * 1000\n",
    "\n",
    "print(f\"‚úÖ Response received!\\n\")\n",
    "print(f\"üìä Performance Metrics:\")\n",
    "print(f\"   Response time: {response_time:.0f}ms\")\n",
    "print(f\"   Checkpoint used: {new_response['metadata'].get('checkpointUsed', False)}\")\n",
    "print(f\"   Context truncated: {new_response['metadata'].get('contextTruncated', False)}\")\n",
    "print(f\"   Prompt tokens: {new_response['metadata'].get('promptTokens', 'N/A')}\")\n",
    "print(f\"   Messages in context: {new_response['metadata'].get('contextMessageCount', 'N/A')}\")\n",
    "print()\n",
    "\n",
    "print(\"üí° Notice: Even with 20+ messages, response is fast because checkpoint\")\n",
    "print(\"   summarizes old context and only sends recent messages + summary!\")\n",
    "print()\n",
    "print(\"‚ïê\" * 70)"
   ],
   "metadata": {
    "id": "performance"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üîê Part 8: Message Immutability & Security"
   ],
   "metadata": {
    "id": "part8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"‚ïê\" * 70)\n",
    "print(\"üîê MESSAGE IMMUTABILITY & SECURITY\")\n",
    "print(\"‚ïê\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"ChatRoutes implements enterprise-grade message immutability:\\n\")\n",
    "\n",
    "print(\"‚úÖ Database-Level Protection:\")\n",
    "print(\"   ‚Ä¢ PostgreSQL triggers prevent message modification\")\n",
    "print(\"   ‚Ä¢ Immutable fields: content, role, contentHash, conversationId, branchId\")\n",
    "print(\"   ‚Ä¢ Any attempt to modify triggers database error\\n\")\n",
    "\n",
    "print(\"‚úÖ Cryptographic Hashing:\")\n",
    "print(\"   ‚Ä¢ Each message has SHA-256 canonical hash\")\n",
    "print(\"   ‚Ä¢ Hash computed from: role + content + metadata (deterministic order)\")\n",
    "print(\"   ‚Ä¢ Tamper detection: hash mismatch = data corruption\\n\")\n",
    "\n",
    "print(\"‚úÖ Soft Delete:\")\n",
    "print(\"   ‚Ä¢ Deleted messages marked with deletedAt timestamp\")\n",
    "print(\"   ‚Ä¢ Original content preserved for audit\")\n",
    "print(\"   ‚Ä¢ Delete reason tracked for compliance\\n\")\n",
    "\n",
    "print(\"‚úÖ Complete Audit Trail:\")\n",
    "print(\"   ‚Ä¢ All operations logged to audit_logs table\")\n",
    "print(\"   ‚Ä¢ Who, what, when, why recorded\")\n",
    "print(\"   ‚Ä¢ Compliance-ready (HIPAA, GDPR, SOC2)\\n\")\n",
    "\n",
    "message = messages[0]\n",
    "print(f\"Example Message:\")\n",
    "print(f\"   ID: {message['id']}\")\n",
    "print(f\"   Content Hash: {message.get('contentHash', 'N/A')[:32]}...\")\n",
    "print(f\"   Role: {message['role']}\")\n",
    "print(f\"   Created: {message['createdAt']}\")\n",
    "print()\n",
    "\n",
    "print(\"üí° Benefits:\")\n",
    "print(\"   ‚Ä¢ Messages cannot be tampered with\")\n",
    "print(\"   ‚Ä¢ Complete conversation history preserved\")\n",
    "print(\"   ‚Ä¢ Regulatory compliance guaranteed\")\n",
    "print(\"   ‚Ä¢ Audit trail for all operations\")\n",
    "print()\n",
    "print(\"‚ïê\" * 70)"
   ],
   "metadata": {
    "id": "security"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üéØ Part 9: Advanced Checkpoint Operations"
   ],
   "metadata": {
    "id": "part9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Testing checkpoint retrieval...\\n\")\n",
    "\n",
    "retrieved = client.checkpoints.get(checkpoint_id)\n",
    "\n",
    "print(f\"‚úÖ Checkpoint retrieved!\\n\")\n",
    "print(f\"Checkpoint Details:\")\n",
    "print(f\"   ID: {retrieved['id']}\")\n",
    "print(f\"   Conversation: {retrieved['conversationId']}\")\n",
    "print(f\"   Branch: {retrieved['branchId']}\")\n",
    "print(f\"   Anchor Message: {retrieved['anchorMessageId']}\")\n",
    "print(f\"   Token Count: {retrieved['tokenCount']}\")\n",
    "print(f\"   Created: {retrieved['createdAt']}\\n\")\n",
    "\n",
    "print(f\"Summary Preview:\")\n",
    "print(f\"{retrieved['summary'][:400]}...\")"
   ],
   "metadata": {
    "id": "checkpoint-ops"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\nRecreating checkpoint with latest conversation state...\\n\")\n",
    "\n",
    "recreated = client.checkpoints.recreate(checkpoint_id)\n",
    "\n",
    "print(f\"‚úÖ Checkpoint recreated!\\n\")\n",
    "print(f\"Old vs New Comparison:\")\n",
    "print(f\"   Old token count: {retrieved['tokenCount']}\")\n",
    "print(f\"   New token count: {recreated['tokenCount']}\")\n",
    "print(f\"   Token difference: {recreated['tokenCount'] - retrieved['tokenCount']}\")\n",
    "print()\n",
    "print(f\"üí° Recreate updates checkpoint to include new messages added since creation\")"
   ],
   "metadata": {
    "id": "recreate-checkpoint"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üìà Part 10: Scaling Analysis"
   ],
   "metadata": {
    "id": "part10"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"‚ïê\" * 70)\n",
    "print(\"üìà SCALING SCENARIOS\")\n",
    "print(\"‚ïê\" * 70)\n",
    "print()\n",
    "\n",
    "scenarios = [\n",
    "    {\"name\": \"Startup\", \"conversations\": 1_000, \"avg_messages\": 80},\n",
    "    {\"name\": \"Growth Stage\", \"conversations\": 10_000, \"avg_messages\": 80},\n",
    "    {\"name\": \"Enterprise\", \"conversations\": 100_000, \"avg_messages\": 80},\n",
    "    {\"name\": \"Large Enterprise\", \"conversations\": 1_000_000, \"avg_messages\": 80}\n",
    "]\n",
    "\n",
    "print(f\"Assuming:\")\n",
    "print(f\"   ‚Ä¢ Average messages per conversation: 80\")\n",
    "print(f\"   ‚Ä¢ Average tokens per message: 100\")\n",
    "print(f\"   ‚Ä¢ Cost per million tokens: $15\\n\")\n",
    "\n",
    "for scenario in scenarios:\n",
    "    convos = scenario['conversations']\n",
    "    msgs = scenario['avg_messages']\n",
    "    \n",
    "    tokens_without = convos * msgs * 100\n",
    "    tokens_with = convos * (500 + min(50, msgs) * 100)\n",
    "    \n",
    "    cost_without = (tokens_without / 1_000_000) * 15\n",
    "    cost_with = (tokens_with / 1_000_000) * 15\n",
    "    \n",
    "    monthly_savings = cost_without - cost_with\n",
    "    annual_savings = monthly_savings * 12\n",
    "    \n",
    "    print(f\"‚îÄ\" * 70)\n",
    "    print(f\"{scenario['name']} ({convos:,} conversations/month):\")\n",
    "    print(f\"‚îÄ\" * 70)\n",
    "    print(f\"   WITHOUT Checkpoints: ${cost_without:,.2f}/month\")\n",
    "    print(f\"   WITH Checkpoints:    ${cost_with:,.2f}/month\")\n",
    "    print(f\"   Monthly Savings:     ${monthly_savings:,.2f}\")\n",
    "    print(f\"   Annual Savings:      ${annual_savings:,.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚ïê\" * 70)\n",
    "print(\"üí° Key Insight: Savings scale linearly with usage!\")\n",
    "print(\"   The more conversations you have, the more you save.\")\n",
    "print(\"‚ïê\" * 70)"
   ],
   "metadata": {
    "id": "scaling"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üéì Part 11: Best Practices & Tips"
   ],
   "metadata": {
    "id": "part11"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"‚ïê\" * 70)\n",
    "print(\"üéì BEST PRACTICES FOR USING CHATROUTES\")\n",
    "print(\"‚ïê\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Checkpoint Management:\")\n",
    "print(\"   1. Let auto-checkpoints handle most conversations (every 50 messages)\")\n",
    "print(\"   2. Create manual checkpoints at logical conversation boundaries\")\n",
    "print(\"   3. Recreate checkpoints when conversation changes significantly\")\n",
    "print(\"   4. Delete old checkpoints when no longer needed\\n\")\n",
    "\n",
    "print(\"‚úÖ Branching Strategy:\")\n",
    "print(\"   1. Use branches to explore alternative responses\")\n",
    "print(\"   2. Create branches before major conversation pivots\")\n",
    "print(\"   3. Name branches descriptively (e.g., 'Technical Approach', 'Business Focus')\")\n",
    "print(\"   4. Merge successful branches back to main\\n\")\n",
    "\n",
    "print(\"‚úÖ Token Optimization:\")\n",
    "print(\"   1. Checkpoints automatically optimize for conversations >50 messages\")\n",
    "print(\"   2. Monitor metadata.promptTokens to track token usage\")\n",
    "print(\"   3. Use metadata.checkpointUsed to verify optimization is active\")\n",
    "print(\"   4. Consider recreating checkpoints every 100-200 new messages\\n\")\n",
    "\n",
    "print(\"‚úÖ Performance:\")\n",
    "print(\"   1. Checkpoints improve response time by 2-3x for long conversations\")\n",
    "print(\"   2. Context assembly is <5ms (industry-leading)\")\n",
    "print(\"   3. Use streaming for real-time responses\")\n",
    "print(\"   4. Batch operations when possible\\n\")\n",
    "\n",
    "print(\"‚úÖ Security & Compliance:\")\n",
    "print(\"   1. Messages are immutable - use soft delete when needed\")\n",
    "print(\"   2. All operations are logged in audit trail\")\n",
    "print(\"   3. Content hashing ensures data integrity\")\n",
    "print(\"   4. GDPR/HIPAA compliant out of the box\\n\")\n",
    "\n",
    "print(\"‚ïê\" * 70)"
   ],
   "metadata": {
    "id": "best-practices"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üèÅ Summary & Key Takeaways"
   ],
   "metadata": {
    "id": "summary"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"‚ïê\" * 70)\n",
    "print(\"üèÜ CHATROUTES: KEY FEATURES & BENEFITS\")\n",
    "print(\"‚ïê\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"üí∞ COST SAVINGS:\")\n",
    "print(\"   ‚úì 60-70% token reduction for long conversations\")\n",
    "print(\"   ‚úì $17K+ annual savings (10K conversations/month)\")\n",
    "print(\"   ‚úì ROI of 342% in first year\")\n",
    "print(\"   ‚úì Savings scale linearly with usage\\n\")\n",
    "\n",
    "print(\"‚ö° PERFORMANCE:\")\n",
    "print(\"   ‚úì 2-3x faster responses for long conversations\")\n",
    "print(\"   ‚úì <5ms context assembly (10x better than target)\")\n",
    "print(\"   ‚úì Consistent performance regardless of conversation length\")\n",
    "print(\"   ‚úì Real-time streaming support\\n\")\n",
    "\n",
    "print(\"üîê SECURITY & COMPLIANCE:\")\n",
    "print(\"   ‚úì 100% immutable messages (database-enforced)\")\n",
    "print(\"   ‚úì SHA-256 cryptographic hashing\")\n",
    "print(\"   ‚úì Complete audit trails\")\n",
    "print(\"   ‚úì HIPAA, GDPR, SOC2 compliant\\n\")\n",
    "\n",
    "print(\"üå≥ ADVANCED FEATURES:\")\n",
    "print(\"   ‚úì Conversation branching for exploring alternatives\")\n",
    "print(\"   ‚úì AI-powered checkpointing for cost optimization\")\n",
    "print(\"   ‚úì Multi-model support (GPT-5, Claude, GPT-4, etc.)\")\n",
    "print(\"   ‚úì Intelligent context assembly\\n\")\n",
    "\n",
    "print(\"üéØ IDEAL FOR:\")\n",
    "print(\"   ‚Ä¢ Customer support with long conversation threads\")\n",
    "print(\"   ‚Ä¢ Technical documentation assistants\")\n",
    "print(\"   ‚Ä¢ Educational tutoring systems\")\n",
    "print(\"   ‚Ä¢ Multi-session project discussions\")\n",
    "print(\"   ‚Ä¢ Any application with conversations >50 messages\\n\")\n",
    "\n",
    "print(\"‚ïê\" * 70)\n",
    "print()\n",
    "print(\"üìö Resources:\")\n",
    "print(\"   ‚Ä¢ Documentation: https://docs.chatroutes.com\")\n",
    "print(\"   ‚Ä¢ API Reference: https://docs.chatroutes.com/api\")\n",
    "print(\"   ‚Ä¢ Python SDK: https://github.com/chatroutes/chatroutes-python-sdk\")\n",
    "print(\"   ‚Ä¢ JavaScript SDK: https://github.com/chatroutes/chatroutes-sdk\")\n",
    "print()\n",
    "print(\"üöÄ Ready to get started? Sign up at https://chatroutes.com\")\n",
    "print()\n",
    "print(\"‚ïê\" * 70)"
   ],
   "metadata": {
    "id": "final-summary"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üßπ Cleanup (Optional)"
   ],
   "metadata": {
    "id": "cleanup"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Cleaning up test conversations...\\n\")\n",
    "\n",
    "try:\n",
    "    client.conversations.delete(conv_id)\n",
    "    print(f\"‚úì Deleted conversation: {conv_id}\")\n",
    "except:\n",
    "    print(f\"  Note: Conversation may already be deleted\")\n",
    "\n",
    "try:\n",
    "    client.conversations.delete(long_conv_id)\n",
    "    print(f\"‚úì Deleted conversation: {long_conv_id}\")\n",
    "except:\n",
    "    print(f\"  Note: Conversation may already be deleted\")\n",
    "\n",
    "print(\"\\n‚úÖ Cleanup complete!\")"
   ],
   "metadata": {
    "id": "cleanup-code"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}