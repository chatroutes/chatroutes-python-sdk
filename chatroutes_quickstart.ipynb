{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chatroutes-header"
   },
   "source": [
    "# ğŸš€ ChatRoutes Python SDK - Quick Start Guide\n",
    "\n",
    "[![PyPI](https://img.shields.io/pypi/v/chatroutes.svg)](https://pypi.org/project/chatroutes/)\n",
    "[![Python](https://img.shields.io/pypi/pyversions/chatroutes.svg)](https://pypi.org/project/chatroutes/)\n",
    "\n",
    "Welcome to ChatRoutes! This notebook will help you get started with the ChatRoutes Python SDK.\n",
    "\n",
    "## âš ï¸ Beta Release Notice\n",
    "\n",
    "ChatRoutes is currently in **beta**. The API may change without maintaining backward compatibility. Please use with caution in production environments.\n",
    "\n",
    "## ğŸ”‘ Getting Your API Key\n",
    "\n",
    "**IMPORTANT:** Before you begin, you need to get your API key:\n",
    "\n",
    "1. **Visit** [chatroutes.com](https://chatroutes.com)\n",
    "2. **Sign up** for a free account\n",
    "3. **Go to Dashboard** â†’ Navigate to the **API section**\n",
    "4. **Generate** your API key\n",
    "5. **Copy** the API key and paste it below when prompted\n",
    "\n",
    "## ğŸ¤– Supported Models\n",
    "\n",
    "**OpenAI:**\n",
    "- **`gpt-5`** (default) - OpenAI's GPT-5\n",
    "\n",
    "**Anthropic Claude 4:**\n",
    "- **`claude-opus-4-1`** - Claude Opus 4.1 (most capable)\n",
    "- **`claude-opus-4`** - Claude Opus 4\n",
    "- **`claude-opus-4-0`** - Claude Opus 4.0\n",
    "- **`claude-sonnet-4-5`** - Claude Sonnet 4.5 (best for coding)\n",
    "- **`claude-sonnet-4-0`** - Claude Sonnet 4.0\n",
    "\n",
    "**Anthropic Claude 3:**\n",
    "- **`claude-3-7-sonnet-latest`** - Claude 3.7 Sonnet (latest)\n",
    "- **`claude-3-5-haiku-latest`** - Claude 3.5 Haiku (fastest)\n",
    "\n",
    "**Important**: Use these exact model names. Other model names are not supported.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-section"
   },
   "source": [
    "## ğŸ“¦ Step 1: Install ChatRoutes SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-cell"
   },
   "outputs": [],
   "source": "!pip install -q chatroutes\n!pip show chatroutes\nprint(\"âœ… ChatRoutes SDK installed successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## ğŸ” Step 2: Set Up Your API Key\n",
    "\n",
    "Enter your API key below. You can get it from [chatroutes.com](https://chatroutes.com) â†’ Dashboard â†’ API section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-cell"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from chatroutes import ChatRoutes\n",
    "\n",
    "# Enter your API key (it will be hidden)\n",
    "api_key = getpass('Enter your ChatRoutes API key: ')\n",
    "\n",
    "# Initialize the ChatRoutes client\n",
    "client = ChatRoutes(api_key=api_key)\n",
    "\n",
    "print(\"âœ… ChatRoutes client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-1-section"
   },
   "source": [
    "## ğŸ’¬ Step 3: Create Your First Conversation\n",
    "\n",
    "Let's create a conversation and send a message!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-1-cell"
   },
   "outputs": [],
   "source": [
    "# Create a new conversation\n",
    "conversation = client.conversations.create({\n",
    "    'title': 'My First ChatRoutes Conversation',\n",
    "    'model': 'gpt-5'  # Try: claude-opus-4-1, claude-sonnet-4-5, etc.\n",
    "})\n",
    "\n",
    "print(f\"âœ… Created conversation: {conversation['title']}\")\n",
    "print(f\"ğŸ“ Conversation ID: {conversation['id']}\")\n",
    "print(f\"ğŸ¤– Model: {conversation['model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-2-section"
   },
   "source": [
    "## ğŸ“¤ Step 4: Send a Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-2-cell"
   },
   "outputs": [],
   "source": [
    "# Send a message to the conversation\n",
    "response = client.messages.send(\n",
    "    conversation['id'],\n",
    "    {\n",
    "        'content': 'Hello! Can you explain what ChatRoutes is in one sentence?',\n",
    "        'model': 'gpt-5'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¤– AI Response:\")\n",
    "print(response['message']['content'])\n",
    "print(f\"\\nğŸ“Š Model: {response['model']}\")\n",
    "print(f\"ğŸ”¢ Tokens used: {response['usage']['totalTokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-3-section"
   },
   "source": "## ğŸŒŠ Step 5: Try Streaming Responses\n\nChatRoutes supports **real-time streaming** for faster user experience!\n\n### What is Streaming?\n\nInstead of waiting for the complete response, streaming sends the AI's response **as it's being generated**:\n\n**Non-Streaming (Traditional):**\n```\n[Wait 3 seconds...] â†’ Full response appears at once\n```\n\n**Streaming (Real-Time):**\n```\n[0.5s] \"Why did...\"\n[1.0s] \"Why did the programmer...\"\n[1.5s] \"Why did the programmer quit? Because...\"\n[2.0s] \"Why did the programmer quit? Because they didn't get arrays!\"\n```\n\n### ğŸ¥ Watch for the Effect!\n\nIn the next cell, you'll see the response appear **word-by-word** in real-time. This is how ChatGPT and Claude feel fast and responsive!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-3-cell"
   },
   "outputs": [],
   "source": "import sys\nimport time\n\nprint(\"ğŸŒŠ Streaming response (watch it appear in real-time):\\n\")\nprint(\"â”€\" * 60)\n\n# Track streaming metadata\nchunks_received = 0\nstart_time = time.time()\n\n# Define callback for streaming chunks\ndef on_chunk(chunk):\n    global chunks_received\n    if chunk.get('type') == 'content' and chunk.get('content'):\n        chunks_received += 1\n        # Print chunk immediately with flush\n        print(chunk['content'], end='', flush=True)\n        sys.stdout.flush()  # Force output in Jupyter\n\ndef on_complete(message):\n    elapsed = time.time() - start_time\n    print(f\"\\n\")\n    print(\"â”€\" * 60)\n    print(f\"âœ… Streaming complete!\")\n    print(f\"ğŸ“Š Streaming Stats:\")\n    print(f\"   â€¢ Chunks received: {chunks_received}\")\n    print(f\"   â€¢ Time elapsed: {elapsed:.2f} seconds\")\n    print(f\"   â€¢ Message ID: {message['id']}\")\n    print(f\"   â€¢ Average chunk rate: {chunks_received/elapsed:.1f} chunks/sec\")\n\nprint(\"â³ Waiting for first chunk...\\n\")\n\n# Send a message with streaming\nclient.messages.stream(\n    conversation['id'],\n    {\n        'content': 'Tell me a short joke about programming.',\n        'model': 'gpt-5'\n    },\n    on_chunk=on_chunk,\n    on_complete=on_complete\n)\n\nprint(\"\\nğŸ’¡ Notice: The response appeared word-by-word, not all at once!\")\nprint(\"   This is real-time streaming from the AI model.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-4-section"
   },
   "source": [
    "## ğŸŒ³ Step 6: Create a Branch (Alternative Response)\n",
    "\n",
    "One of ChatRoutes' unique features is conversation branching - explore alternative responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-4-cell"
   },
   "outputs": [],
   "source": "# Create a branch for alternative responses\nbranch = client.branches.create(\n    conversation['id'],\n    {\n        'title': 'Alternative Response',\n        'contextMode': 'FULL'\n    }\n)\n\nprint(f\"âœ… Created branch: {branch['title']}\")\nprint(f\"ğŸŒ¿ Branch ID: {branch['id']}\")\n\n# Send a message to the branch using the branches resource\n# NOTE: This creates TWO messages in the branch:\n#   1. Your user message (the question)\n#   2. The AI's assistant message (the response)\nbranch_response = client.branches.send_message(\n    conversation['id'],\n    branch['id'],\n    {\n        'content': 'Now tell me a joke about AI instead.',\n        'model': 'gpt-5'\n    }\n)\n\nprint(\"\\nğŸŒ¿ Branch response:\")\nprint(branch_response['assistantMessage']['content'])\nprint(\"\\nğŸ’¡ Note: Each message exchange creates 2 messages (user + assistant)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-claude-section"
   },
   "source": [
    "## ğŸ­ Step 7: Try Different Claude Models\n",
    "\n",
    "Test various Claude models for different use cases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-claude-cell"
   },
   "outputs": [],
   "source": [
    "# Claude Opus 4.1 - Most capable\n",
    "opus_conv = client.conversations.create({\n",
    "    'title': 'Claude Opus 4.1 - Most Capable',\n",
    "    'model': 'claude-opus-4-1'\n",
    "})\n",
    "\n",
    "opus_response = client.messages.send(\n",
    "    opus_conv['id'],\n",
    "    {'content': 'Explain quantum entanglement in simple terms.', 'model': 'claude-opus-4-1'}\n",
    ")\n",
    "print(\"ğŸ­ Claude Opus 4.1 (Most Capable):\")\n",
    "print(opus_response['message']['content'][:200] + \"...\\n\")\n",
    "\n",
    "# Claude Sonnet 4.5 - Best for coding\n",
    "sonnet_conv = client.conversations.create({\n",
    "    'title': 'Claude Sonnet 4.5 - Best for Coding',\n",
    "    'model': 'claude-sonnet-4-5'\n",
    "})\n",
    "\n",
    "sonnet_response = client.messages.send(\n",
    "    sonnet_conv['id'],\n",
    "    {'content': 'Write a Python function to check if a number is prime.', 'model': 'claude-sonnet-4-5'}\n",
    ")\n",
    "print(\"ğŸ’» Claude Sonnet 4.5 (Best for Coding):\")\n",
    "print(sonnet_response['message']['content'][:200] + \"...\\n\")\n",
    "\n",
    "# Claude 3.5 Haiku - Fastest\n",
    "haiku_conv = client.conversations.create({\n",
    "    'title': 'Claude 3.5 Haiku - Fastest',\n",
    "    'model': 'claude-3-5-haiku-latest'\n",
    "})\n",
    "\n",
    "haiku_response = client.messages.send(\n",
    "    haiku_conv['id'],\n",
    "    {'content': 'Summarize AI in one sentence.', 'model': 'claude-3-5-haiku-latest'}\n",
    ")\n",
    "print(\"âš¡ Claude 3.5 Haiku (Fastest):\")\n",
    "print(haiku_response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-5-section"
   },
   "source": [
    "## ğŸ“‹ Step 8: List Your Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-5-cell"
   },
   "outputs": [],
   "source": "# List all conversations\nresult = client.conversations.list({\n    'page': 1,\n    'limit': 5,\n    'filter': 'all'\n})\n\nprint(f\"ğŸ“Š Total conversations: {result['total']}\")\nprint(f\"ğŸ“„ Page {result['page']} of {result.get('pages', '?')}\")\nprint(f\"â¡ï¸ Has next page: {result.get('hasNext', False)}\\n\")\n\nfor conv in result['data']:\n    print(f\"ğŸ’¬ {conv['title']}\")\n    print(f\"   ID: {conv['id']}\")\n    print(f\"   Messages: {conv.get('messageCount', 0)}\")\n    print(f\"   Branches: {conv.get('branchCount', 0)}\")\n    print(f\"   Created: {conv['createdAt']}\")\n    print(f\"   Updated: {conv['updatedAt']}\")\n    print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example-6-section"
   },
   "source": [
    "## ğŸŒ² Step 9: View Conversation Tree\n",
    "\n",
    "See the structure of your conversation with all its branches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example-6-cell"
   },
   "outputs": [],
   "source": "# Get conversation tree\ntree = client.conversations.get_tree(conversation['id'])\n\ndef print_tree_branch(branch_node, indent=0):\n    \"\"\"Print a branch and its messages\"\"\"\n    prefix = \"  \" * indent\n    branch = branch_node['branch']\n    \n    print(f\"{prefix}ğŸŒ¿ Branch: {branch['title']}\")\n    print(f\"{prefix}   Messages: {branch['_count']['messages']}\")\n    print(f\"{prefix}   Active: {branch['isActive']}\")\n    \n    # Print child branches recursively\n    for child in branch_node.get('children', []):\n        print_tree_branch(child, indent + 1)\n\nprint(\"ğŸŒ² Conversation Tree:\\n\")\nprint(f\"Conversation: {tree['conversation']['title']}\")\nprint(f\"Model: {tree['conversation']['model']}\")\nprint(f\"Total branches: {len(tree['branches'])}\\n\")\n\n# Print all branches\nfor branch_node in tree['branches']:\n    print_tree_branch(branch_node)\n\nprint(\"\\nğŸ’¡ Message Count Explanation:\")\nprint(\"   Each conversation exchange creates 2 messages:\")\nprint(\"   â€¢ 1 user message (your question)\")\nprint(\"   â€¢ 1 assistant message (AI's response)\")\nprint(\"   So if you see '4 messages', that's 2 exchanges (2 Q&A pairs)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup-section"
   },
   "source": [
    "## ğŸ§¹ Optional: Clean Up\n",
    "\n",
    "Delete the test conversations if you want to clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup-cell"
   },
   "outputs": [],
   "source": [
    "# Uncomment to delete the conversations\n",
    "# client.conversations.delete(conversation['id'])\n",
    "# client.conversations.delete(opus_conv['id'])\n",
    "# client.conversations.delete(sonnet_conv['id'])\n",
    "# client.conversations.delete(haiku_conv['id'])\n",
    "# print(\"âœ… Conversations deleted\")\n",
    "\n",
    "print(\"â„¹ï¸ Uncomment the code above to delete the test conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resources-section"
   },
   "source": [
    "## ğŸ“š Next Steps\n",
    "\n",
    "Congratulations! You've learned the basics of ChatRoutes. Here are some resources to help you go further:\n",
    "\n",
    "### ğŸ“– Documentation\n",
    "- [GitHub Repository](https://github.com/chatroutes/chatroutes-python-sdk)\n",
    "- [API Documentation](https://docs.chatroutes.com)\n",
    "- [Quick Start Guide](https://github.com/chatroutes/chatroutes-python-sdk/blob/main/QUICKSTART.md)\n",
    "\n",
    "### ğŸ’¡ Examples\n",
    "- [Basic Usage](https://github.com/chatroutes/chatroutes-python-sdk/blob/main/examples/basic_usage.py)\n",
    "- [Streaming](https://github.com/chatroutes/chatroutes-python-sdk/blob/main/examples/streaming_example.py)\n",
    "- [Branching](https://github.com/chatroutes/chatroutes-python-sdk/blob/main/examples/branching_example.py)\n",
    "- [Error Handling](https://github.com/chatroutes/chatroutes-python-sdk/blob/main/examples/error_handling.py)\n",
    "\n",
    "### ğŸ¤– Supported Models\n",
    "\n",
    "**OpenAI:**\n",
    "- `gpt-5` (default)\n",
    "\n",
    "**Anthropic Claude 4:**\n",
    "- `claude-opus-4-1` (most capable)\n",
    "- `claude-opus-4`\n",
    "- `claude-opus-4-0`\n",
    "- `claude-sonnet-4-5` (best for coding)\n",
    "- `claude-sonnet-4-0`\n",
    "\n",
    "**Anthropic Claude 3:**\n",
    "- `claude-3-7-sonnet-latest`\n",
    "- `claude-3-5-haiku-latest` (fastest)\n",
    "\n",
    "### ğŸ”§ Key Features to Explore\n",
    "\n",
    "1. **Multiple Models**: Switch between 8+ AI models for different use cases\n",
    "2. **Conversation Branching**: Explore alternative conversation paths\n",
    "3. **Streaming**: Real-time response streaming\n",
    "4. **Message History**: Access and manage conversation history\n",
    "5. **Branch Merging**: Merge branches back into main conversation\n",
    "\n",
    "### ğŸ’¬ Support\n",
    "- Email: support@chatroutes.com\n",
    "- GitHub Issues: [Report a bug](https://github.com/chatroutes/chatroutes-python-sdk/issues)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy coding with ChatRoutes!** ğŸš€"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ChatRoutes Python SDK - Quick Start",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}