{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# ğŸš€ ChatRoutes Complete Feature Demo\n\n## Comprehensive demonstration of ChatRoutes API features\n\nThis notebook demonstrates:\n- âœ… **Authentication & Setup**\n- âœ… **Conversation Management**\n- âœ… **Branching & Alternative Responses**\n- âœ… **Checkpoint System** (60-70% Token Savings!)\n- âœ… **Tree Visualization** (DAG Structure)\n- âœ… **Message Immutability** (Cryptographic Integrity)\n- âœ… **Token Optimization & Cost Savings**\n- âœ… **Performance Comparison**\n\n---\n\n## âš ï¸ Token Usage - READ THIS FIRST!\n\n**This demo is OPTIMIZED for your FREE quota (100,000 tokens/month)**\n\n### Expected Token Usage:\n- **Part 1-2** (Basic + Branching): ~2,000 tokens\n- **Part 3** (Build conversation): **CONFIGURABLE**\n  - SMALL: ~3,000 tokens (Too few for good checkpoint demo)\n  - MEDIUM: ~7,000 tokens (âœ… **RECOMMENDED** - Good balance!)\n  - LARGE: ~15,000 tokens (Better demo, uses more quota)\n- **Total demo**: ~9,000 tokens (MEDIUM mode = 9% of quota)\n\nğŸ’¡ **Best Practice**: Use MEDIUM mode (default) for best checkpoint demonstration while staying quota-friendly!\n\n---\n\n**What is ChatRoutes?**\n\nChatRoutes is an advanced conversation management platform with:\n- Multi-model AI support (GPT-5, Claude Sonnet 4.5, GPT-4, etc.)\n- Conversation branching for exploring alternatives\n- Intelligent checkpointing for cost optimization\n- Tree/DAG visualization for understanding conversation flow\n- Enterprise-grade data immutability and security\n\n---\n\n**ğŸ“Š Key Benefits Demonstrated:**\n- **60-70% token reduction** for long conversations (50-100+ messages)\n- **$17K+ annual savings** (for 10K conversations/month)\n- **2-3x faster responses** for long conversations\n- **100% immutable** message history with cryptographic hashing\n- **Complete audit trails** for HIPAA, GDPR, SOC2 compliance",
   "metadata": {
    "id": "intro"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“¦ Installation & Setup"
   ],
   "metadata": {
    "id": "setup"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install chatroutes -q\n",
    "print(\"âœ… ChatRoutes SDK installed successfully!\")"
   ],
   "metadata": {
    "id": "install"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "api_key = getpass('Enter your ChatRoutes API Key: ')\n",
    "os.environ['CHATROUTES_API_KEY'] = api_key\n",
    "\n",
    "print(\"âœ… API key configured!\")"
   ],
   "metadata": {
    "id": "config"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from chatroutes import ChatRoutes\n",
    "\n",
    "client = ChatRoutes(api_key=api_key)\n",
    "\n",
    "print(\"âœ… ChatRoutes client initialized!\")\n",
    "print(f\"   Base URL: {client.base_url}\")"
   ],
   "metadata": {
    "id": "client-init"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ’¬ Part 1: Basic Conversation Management"
   ],
   "metadata": {
    "id": "part1"
   }
  },
  {
   "cell_type": "code",
   "source": "print(\"Creating a fresh conversation...\\n\")\n\n# Using Claude Sonnet 4.5 for reliable demo experience\nconversation = client.conversations.create({\n    'title': f'ChatRoutes Demo {int(time.time())}',\n    'model': 'claude-sonnet-4-5'\n})\n\nprint(f\"âœ… Conversation created!\")\nprint(f\"   ID: {conversation['id']}\")\nprint(f\"   Title: {conversation['title']}\")\nprint(f\"   Model: claude-sonnet-4-5 (Claude Sonnet 4.5)\")\nprint(f\"   Created: {conversation['createdAt']}\")\n\nconv_id = conversation['id']",
   "metadata": {
    "id": "create-conversation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"Sending first message...\\n\")\n\nresponse = client.messages.send(\n    conv_id,\n    {\n        'content': 'Explain quantum computing in simple terms.',\n        'model': 'claude-sonnet-4-5'\n    }\n)\n\nassistant_msg = response.get('message') or response.get('assistantMessage')\n\nprint(f\"âœ… Message sent and response received!\\n\")\nprint(f\"AI Response ({response['model']}):\")\nprint(f\"{assistant_msg['content'][:300]}...\\n\")\n\nprint(f\"ğŸ“Š Metadata:\")\nprint(f\"   Message ID: {assistant_msg['id']}\")\nprint(f\"   Tokens Used: {response.get('usage', {}).get('totalTokens', 'N/A')}\")",
   "metadata": {
    "id": "send-message"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸŒ³ Part 2: Conversation Branching & Alternative Responses\n\n### What is Branching?\n\nBranching lets you explore **multiple alternative responses** from the same point in a conversation:\n- Try different **creativity levels** (temperature settings)\n- Explore different **explanation styles** (technical, analogy, ELI5)\n- Compare **multiple models** side-by-side\n- Keep **all variations** without losing the original\n\n### ğŸ›ï¸ Temperature Control\n\nTemperature controls AI creativity:\n- **0.0-0.4**: Conservative (factual, deterministic, consistent)\n- **0.5-0.8**: Balanced (good mix of accuracy and creativity)\n- **0.9-1.5**: Creative (diverse, imaginative, varied)\n- **1.6-2.0**: Highly creative (experimental, unpredictable)\n\n### ğŸ¯ Real-World Use Cases\n\n- **Customer Support**: Try formal vs. casual tone\n- **Content Writing**: Compare different writing styles\n- **Code Generation**: Explore multiple implementation approaches\n- **Education**: Present concepts in different difficulty levels",
   "metadata": {
    "id": "part2"
   }
  },
  {
   "cell_type": "code",
   "source": "print(\"Creating multiple branches with different creativity levels...\\n\")\n\n# Store all variations for comparison\nvariations = []\n\n# Define branch configurations\n# Each will explore \"Explain quantum computing\" with different approaches\nbranch_configs = [\n    {\n        'title': 'Conservative (Factual)',\n        'temperature': 0.3,\n        'instruction': 'Explain quantum computing in precise, technical terms. Be factual and concise.',\n        'label': 'ğŸ¯ Conservative'\n    },\n    {\n        'title': 'Balanced (Standard)',\n        'temperature': 0.7,\n        'instruction': 'Explain quantum computing in a clear, accessible way. Balance accuracy with readability.',\n        'label': 'âš–ï¸ Balanced'\n    },\n    {\n        'title': 'Creative (Analogy)',\n        'temperature': 1.2,\n        'instruction': 'Explain quantum computing using creative analogies and metaphors. Make it fun and memorable!',\n        'label': 'ğŸ¨ Creative'\n    }\n]\n\nprint(f\"Creating {len(branch_configs)} alternative responses with different styles...\\n\")\n\nfor i, config in enumerate(branch_configs, 1):\n    print(f\"[{i}/{len(branch_configs)}] Creating branch: {config['title']}\")\n    print(f\"   Temperature: {config['temperature']} | {config['label']}\")\n    \n    # Create branch\n    branch = client.branches.create(\n        conv_id,\n        {\n            'title': config['title'],\n            'contextMode': 'FULL'\n        }\n    )\n    \n    # Send message with specific temperature and instruction\n    response = client.branches.send_message(\n        conv_id,\n        branch['id'],\n        {\n            'content': config['instruction'],\n            'model': 'claude-sonnet-4-5',\n            'temperature': config['temperature']\n        }\n    )\n    \n    # Store for comparison\n    variations.append({\n        'config': config,\n        'branch_id': branch['id'],\n        'response': response.get('assistantMessage')['content']\n    })\n    \n    print(f\"   âœ“ Response received ({len(response.get('assistantMessage')['content'])} chars)\")\n    print()\n\nprint(\"â•\" * 70)\nprint(\"âœ… All variations created successfully!\")\nprint(\"â•\" * 70)\nprint(f\"   Branches created: {len(variations)}\")\nprint(f\"   Each explores the same topic with different creativity levels\")\nprint(\"â•\" * 70)",
   "metadata": {
    "id": "create-branch"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"\\nğŸ“Š COMPARING ALL VARIATIONS\\n\")\nprint(\"Let's see how temperature and instructions create different responses:\\n\")\nprint(\"â•\" * 70)\n\nfor i, var in enumerate(variations, 1):\n    config = var['config']\n    response = var['response']\n    \n    print(f\"\\n{config['label']} {config['title']}\")\n    print(f\"Temperature: {config['temperature']} | Instruction: {config['instruction'][:50]}...\")\n    print(\"â”€\" * 70)\n    \n    # Show first 300 characters\n    preview = response[:300] + \"...\" if len(response) > 300 else response\n    print(preview)\n    print(\"â”€\" * 70)\n\nprint(\"\\nğŸ’¡ OBSERVATIONS:\\n\")\nprint(\"ğŸ¯ Conservative (temp 0.3):\")\nprint(\"   â€¢ More deterministic and factual\")\nprint(\"   â€¢ Technical terminology\")\nprint(\"   â€¢ Consistent structure\\n\")\n\nprint(\"âš–ï¸ Balanced (temp 0.7):\")\nprint(\"   â€¢ Good mix of accuracy and accessibility\")\nprint(\"   â€¢ Clear explanations\")\nprint(\"   â€¢ Natural language\\n\")\n\nprint(\"ğŸ¨ Creative (temp 1.2):\")\nprint(\"   â€¢ Uses analogies and metaphors\")\nprint(\"   â€¢ More varied vocabulary\")\nprint(\"   â€¢ Engaging storytelling\\n\")\n\nprint(\"âœ… All variations preserved! You can:\")\nprint(\"   â€¢ Review and compare different approaches\")\nprint(\"   â€¢ Choose the best one for your use case\")\nprint(\"   â€¢ Continue conversation from any branch\")\nprint(\"   â€¢ No data lost - complete history maintained\")\n\nprint(\"\\nğŸ’¡ Pro Tip: Use branching to:\")\nprint(\"   â€¢ Test different tones (formal vs casual)\")\nprint(\"   â€¢ Compare models (GPT vs Claude)\")\nprint(\"   â€¢ Explore alternative solutions\")\nprint(\"   â€¢ A/B test content variations\")",
   "metadata": {
    "id": "alt-response"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ¯ Part 3: Building a Long Conversation (Setup for Checkpoints)\n\n### âš ï¸ Token Usage Notice\n\nThis section creates a conversation to demonstrate checkpoints.\n\n**Options:**\n- **SMALL** (3 messages): ~3K tokens - Too few for meaningful checkpoint\n- **MEDIUM** (5 messages): ~6K tokens - âœ… **RECOMMENDED** (Good balance!)\n- **LARGE** (10 messages): ~15K tokens - Better demo but uses more quota\n\n**Your FREE quota: 100,000 tokens/month**\n\nğŸ’¡ **Note:** Checkpoints show MAXIMUM value with 50-100+ messages. This demo proves the concept works, not maximum savings!",
   "metadata": {
    "id": "part3"
   }
  },
  {
   "cell_type": "code",
   "source": "# âš™ï¸ CONFIGURATION: Choose your demo size\n# Change this to 'SMALL', 'MEDIUM', or 'LARGE'\nDEMO_SIZE = 'MEDIUM'  # ğŸ‘ˆ RECOMMENDED - Best balance for checkpoint demo!\n\n# Topic sets for different demo sizes\nTOPICS = {\n    'SMALL': [\n        \"What is Python?\",\n        \"Explain lists vs tuples\",\n        \"What are decorators?\"\n    ],\n    'MEDIUM': [\n        \"What is Python?\",\n        \"Explain lists vs tuples\", \n        \"What are decorators?\",\n        \"Describe generators\",\n        \"What is asyncio?\",\n        \"Explain context managers\",\n        \"What are metaclasses?\"\n    ],\n    'LARGE': [\n        \"What is machine learning?\",\n        \"Explain supervised learning\",\n        \"What are neural networks?\",\n        \"Describe CNNs briefly\",\n        \"What is transfer learning?\",\n        \"Explain gradient descent\",\n        \"What is backpropagation?\",\n        \"Describe transformers\",\n        \"What is BERT?\",\n        \"Explain GPT architecture\"\n    ]\n}\n\ntopics = TOPICS[DEMO_SIZE]\nestimated_tokens = len(topics) * 1000  # More accurate estimate with \"(Keep response under 100 words)\"\n\nprint(\"â•\" * 70)\nprint(f\"ğŸ“Š DEMO CONFIGURATION: {DEMO_SIZE}\")\nprint(\"â•\" * 70)\nprint(f\"   Messages to create: {len(topics)} exchanges ({len(topics) * 2} total messages)\")\nprint(f\"   Estimated tokens: ~{estimated_tokens:,}\")\nprint(f\"   Your FREE quota: 100,000 tokens/month\")\nprint(f\"   Percentage of quota: ~{(estimated_tokens/100000)*100:.1f}%\")\nprint(\"â•\" * 70)\nprint()\n\n# Checkpoint readiness check\nif len(topics) < 5:\n    print(\"âš ï¸  NOTE: This conversation is too short for a meaningful checkpoint demo.\")\n    print(\"   Checkpoints show REAL value with 50-100+ messages.\")\n    print(\"   This will demonstrate HOW it works, not maximum savings.\\n\")\nelif len(topics) >= 5 and len(topics) < 10:\n    print(\"âœ… GOOD: This size is perfect for demonstrating checkpoint technology.\")\n    print(\"   Remember: Real production value appears with 50-100+ messages.\\n\")\n\n# Safety check for LARGE demos\nif DEMO_SIZE == 'LARGE':\n    print(\"âš ï¸  WARNING: LARGE demo will use ~15% of your monthly quota!\")\n    proceed = input(\"   Type 'yes' to proceed: \")\n    if proceed.lower() != 'yes':\n        print(\"   Demo cancelled. Try DEMO_SIZE = 'MEDIUM' instead.\")\n        raise SystemExit(\"Demo cancelled by user\")\n    print()\n\nprint(\"Creating a conversation to demonstrate checkpoints...\\n\")\n\n# Create conversation\nlong_conv = client.conversations.create({\n    'title': f'Demo {DEMO_SIZE} ({int(time.time())})',\n    'model': 'claude-sonnet-4-5'\n})\n\nlong_conv_id = long_conv['id']\nprint(f\"âœ… Conversation created: {long_conv_id}\\n\")\n\nprint(f\"Sending {len(topics)} messages (with concise responses)...\\n\")\n\nmessage_count = 0\ntotal_tokens_used = 0\nresponses = []\n\nfor i, topic in enumerate(topics, 1):\n    print(f\"[{i}/{len(topics)}] {topic}\")\n    \n    try:\n        # Add instruction to keep response brief to save tokens\n        content = f\"{topic} (Keep response under 100 words)\"\n        \n        resp = client.messages.send(\n            long_conv_id,\n            {\n                'content': content,\n                'model': 'claude-sonnet-4-5'\n            }\n        )\n        \n        message_count += 2  # user + assistant\n        tokens = resp.get('usage', {}).get('totalTokens', 0)\n        total_tokens_used += tokens\n        responses.append(resp)\n        \n        print(f\"   âœ“ Response received ({tokens:,} tokens)\")\n        \n        time.sleep(0.5)  # Rate limiting\n    except Exception as e:\n        error_msg = str(e)\n        if 'Quota exceeded' in error_msg:\n            print(f\"   âœ— Quota exceeded! You've used your monthly limit.\")\n            print(f\"   â„¹ï¸  Consider upgrading to PRO (5M tokens/month)\")\n            break\n        else:\n            print(f\"   âœ— Error: {error_msg}\")\n            print(f\"   Continuing with next message...\")\n        continue\n\nprint(f\"\\n{'â•' * 70}\")\nprint(f\"âœ… CONVERSATION CREATED\")\nprint(f\"{'â•' * 70}\")\nprint(f\"   Messages created: {message_count}\")\nprint(f\"   Actual tokens used: {total_tokens_used:,}\")\nprint(f\"   Remaining quota: ~{100000 - total_tokens_used:,} tokens\")\nprint(f\"{'â•' * 70}\\n\")\n\nif total_tokens_used < 1000:\n    print(\"âš ï¸  Note: Very few tokens used. Check if API calls succeeded.\")\nelif DEMO_SIZE == 'SMALL' and total_tokens_used < 5000:\n    print(\"âœ… Great! You used minimal tokens and can run this demo many times!\")\n    print(\"   Feel free to try DEMO_SIZE = 'MEDIUM' next.\")\nelif DEMO_SIZE == 'MEDIUM' and total_tokens_used < 10000:\n    print(\"âœ… Good! You have plenty of quota left to explore more features.\")\n    print(f\"   You can run this demo ~{int((100000-total_tokens_used)/total_tokens_used)} more times!\")\nelse:\n    print(\"â„¹ï¸  You used a significant portion of your quota.\")\n    print(\"   Consider the smaller DEMO_SIZE options for future runs.\")",
   "metadata": {
    "id": "long-conversation"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ğŸ“Š Visualize your quota usage so far\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\n# Calculate usage (estimate Parts 1-2)\nparts_1_2_estimate = 2000\ncumulative_used = parts_1_2_estimate + total_tokens_used\nquota = 100000\nremaining = quota - cumulative_used\npercent_used = (cumulative_used / quota) * 100\n\nfig, ax = plt.subplots(figsize=(12, 3))\n\n# Determine status and color\nif cumulative_used < 20000:\n    bar_color = '#4CAF50'  # Green\n    status_emoji = 'âœ…'\n    status_text = 'Excellent'\nelif cumulative_used < 50000:\n    bar_color = '#FFC107'  # Yellow\n    status_emoji = 'âš ï¸'\n    status_text = 'Moderate'\nelse:\n    bar_color = '#f44336'  # Red\n    status_emoji = 'âŒ'\n    status_text = 'High'\n\n# Draw quota bars\nax.barh(0, cumulative_used, height=0.6, color=bar_color, label=f'Used: {cumulative_used:,} tokens', edgecolor='black', linewidth=2)\nax.barh(0, remaining, left=cumulative_used, height=0.6, color='#e8e8e8', label=f'Remaining: {remaining:,} tokens', edgecolor='gray', linewidth=1)\n\n# Add zone markers\nax.axvline(20000, color='green', linestyle='--', alpha=0.4, linewidth=2, label='Safe Zone')\nax.axvline(50000, color='orange', linestyle='--', alpha=0.4, linewidth=2, label='Caution Zone')\nax.axvline(80000, color='red', linestyle='--', alpha=0.4, linewidth=2, label='Critical Zone')\n\n# Labels and formatting\nax.set_xlim(0, quota)\nax.set_ylim(-0.5, 0.5)\nax.set_xlabel('Tokens', fontsize=13, fontweight='bold')\nax.set_title(f'{status_emoji} Your FREE Quota Usage: {status_text} ({percent_used:.1f}% used)', \n             fontsize=15, fontweight='bold', pad=20)\nax.set_yticks([])\nax.legend(loc='upper right', fontsize=10, framealpha=0.9)\n\n# Add percentage text on bar\nif cumulative_used > 5000:\n    ax.text(cumulative_used / 2, 0, f'{percent_used:.1f}%', \n            ha='center', va='center', fontsize=16, fontweight='bold', \n            color='white' if bar_color != '#FFC107' else 'black',\n            bbox=dict(boxstyle='round,pad=0.3', facecolor=bar_color, alpha=0.8, edgecolor='black', linewidth=2))\n\n# Add milestone markers\nmilestones = [25000, 50000, 75000]\nfor milestone in milestones:\n    if milestone <= quota:\n        ax.text(milestone, -0.35, f'{milestone//1000}K', ha='center', va='top', fontsize=9, color='gray')\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nğŸ’¡ Usage Analysis:\")\nprint(f\"   Demo size used: {DEMO_SIZE}\")\nprint(f\"   Tokens consumed: {cumulative_used:,} ({percent_used:.1f}% of quota)\")\nprint(f\"   Remaining: {remaining:,} tokens\")\nif percent_used < 10:\n    print(f\"   {status_emoji} Great! You can run this demo {int(remaining / estimated_tokens)} more times!\")\nelif percent_used < 30:\n    print(f\"   {status_emoji} Good! Plenty of quota left for exploration.\")\nelse:\n    print(f\"   {status_emoji} Consider using SMALL mode for future runs to conserve quota.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ”– Part 4: NEW FEATURE - Checkpoint System\n\n### What are Checkpoints?\n\nCheckpoints are AI-generated summaries of conversation history that:\n- **Reduce tokens by 60-70%** for long conversations (50-100+ messages)\n- **Maintain context** while optimizing cost\n- **Improve response speed** by 2-3x\n- **Auto-create** every 50 messages (configurable)\n\n### âš ï¸ Demo Honesty: Small Conversation Example\n\n**This demo conversation has 7-14 messages - enough to:**\n- âœ… Show HOW checkpoints work (AI summarization)\n- âœ… Prove the technology functions correctly\n- âŒ NOT show maximum token savings (too few messages)\n\n**Real checkpoint value appears with 50-100+ messages:**\n- Long customer support conversations\n- Multi-session knowledge gathering\n- Extended research discussions\n\n### ğŸ“Š Visual Explanation: How Checkpoints Work\n\n```\nWITHOUT Checkpoints (Traditional):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Send ALL 150 messages to AI  â†’  15,000 tokens             â”‚\nâ”‚  âš ï¸ Slow response + High cost                               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nWITH Checkpoints (ChatRoutes):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Checkpoint Summary (500 tokens)                            â”‚\nâ”‚      +                                                       â”‚\nâ”‚  Recent 50 messages (5,000 tokens)                          â”‚\nâ”‚      =                                                       â”‚\nâ”‚  Total: 5,500 tokens  â†’  63% SAVINGS!                      â”‚\nâ”‚  âœ… Fast response + Low cost                                â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### ğŸ¯ The Magic Formula:\nInstead of sending **ALL messages**, send:\n1. **AI Summary** of old messages (compact: ~500 tokens)\n2. **Recent messages** for context (last 50: ~5K tokens)\n\nResult: **60-70% token reduction** while maintaining full context!\n\n**Think of this demo as \"Hello World\" for checkpoints - proves it works!**",
   "metadata": {
    "id": "part4"
   }
  },
  {
   "cell_type": "code",
   "source": "print(\"Creating a checkpoint for demonstration...\\n\")\n\n# Get conversation with messages\nconversation_data = client.conversations.get(long_conv_id)\nmessages = conversation_data.get('messages', [])\n\nprint(f\"ğŸ“Š Conversation has {len(messages)} messages\")\nprint(f\"ğŸ’¡ NOTE: This is a PROOF-OF-CONCEPT checkpoint demo.\")\nprint(f\"   Real production value appears with 50-100+ messages!\\n\")\n\nif len(messages) > 0:\n    # Find an anchor message (use the middle message)\n    anchor_message = messages[len(messages) // 2]\n    anchor_message_id = anchor_message['id']\n    \n    print(f\"Creating checkpoint at message {len(messages) // 2}...\\n\")\n    \n    # Get branches\n    branches = conversation_data.get('branches', [])\n    main_branch = next((b for b in branches if b.get('isMain', False)), None)\n    \n    if main_branch:\n        branch_id_for_checkpoint = main_branch['id']\n        \n        checkpoint = client.checkpoints.create(\n            long_conv_id,\n            branch_id=branch_id_for_checkpoint,\n            anchor_message_id=anchor_message_id\n        )\n        \n        print(f\"âœ… Checkpoint created successfully!\\n\")\n        print(f\"ğŸ“‹ Checkpoint Details:\")\n        print(f\"   ID: {checkpoint['id']}\")\n        print(f\"   Anchor Message: {checkpoint.get('anchorMessageId') or checkpoint.get('anchor_message_id')}\")\n        print(f\"   Summary Length: {checkpoint.get('tokenCount') or checkpoint.get('token_count')} tokens\")\n        print(f\"   Created: {checkpoint.get('createdAt') or checkpoint.get('created_at')}\\n\")\n        \n        print(f\"ğŸ“ AI-Generated Summary:\")\n        print(f\"{checkpoint['summary']}\\n\")\n        \n        # Calculate demo stats\n        estimated_original_tokens = len(messages) * 150\n        checkpoint_tokens = checkpoint.get('tokenCount') or checkpoint.get('token_count')\n        demo_reduction = ((estimated_original_tokens - checkpoint_tokens) / estimated_original_tokens) * 100\n        \n        print(f\"â”€\" * 70)\n        print(f\"ğŸ“Š DEMO STATS (Small Conversation):\")\n        print(f\"â”€\" * 70)\n        print(f\"   Original messages: {len(messages)} (~{estimated_original_tokens} tokens)\")\n        print(f\"   Checkpoint summary: {checkpoint_tokens} tokens\")\n        print(f\"   Reduction: {demo_reduction:.0f}%\")\n        print(f\"\\nğŸ¯ SCALING TO PRODUCTION:\")\n        print(f\"   With 150 messages: Would save ~9,500 tokens (63% reduction)\")\n        print(f\"   With 500 messages: Would save ~44,500 tokens (89% reduction)\")\n        print(f\"   The longer the conversation, the bigger the savings!\")\n        print(f\"â”€\" * 70)\n        print()\n        \n        checkpoint_id = checkpoint['id']\n    else:\n        print(\"âŒ Could not find main branch for checkpoint creation\")\nelse:\n    print(\"âŒ No messages found in conversation\")",
   "metadata": {
    "id": "create-checkpoint"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Listing all checkpoints for this conversation...\\n\")\n",
    "\n",
    "checkpoints = client.checkpoints.list(long_conv_id)\n",
    "\n",
    "print(f\"âœ… Found {len(checkpoints)} checkpoint(s)\\n\")\n",
    "\n",
    "for i, cp in enumerate(checkpoints, 1):\n",
    "    token_count = cp.get('tokenCount') or cp.get('token_count')\n",
    "    created_at = cp.get('createdAt') or cp.get('created_at')\n",
    "    \n",
    "    print(f\"Checkpoint {i}:\")\n",
    "    print(f\"   ID: {cp['id'][:16]}...\")\n",
    "    print(f\"   Tokens: {token_count}\")\n",
    "    print(f\"   Created: {created_at}\")\n",
    "    print(f\"   Summary: {cp['summary'][:100]}...\")\n",
    "    print()"
   ],
   "metadata": {
    "id": "list-checkpoints"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"Demonstrating immutability features...\\n\")\n\n# Get conversation to show contentHash\nconv_data = client.conversations.get(conv_id)\nall_messages = conv_data.get('messages', [])\n\nif len(all_messages) > 0:\n    sample_message = all_messages[0]\n    content_hash = sample_message.get('contentHash')\n    \n    print(\"ğŸ“ Message with Cryptographic Hash:\")\n    print(\"â”€\" * 60)\n    print(f\"   Message ID: {sample_message['id']}\")\n    print(f\"   Role: {sample_message['role']}\")\n    print(f\"   Content: {sample_message['content'][:60]}...\")\n    \n    if content_hash:\n        print(f\"   Content Hash: {content_hash[:16]}...\")\n        print(f\"   Created: {sample_message.get('createdAt', 'N/A')}\")\n        print(\"â”€\" * 60)\n        print(\"\\nâœ… This SHA-256 hash PROVES the message hasn't been altered!\")\n        print(\"   Any modification would change the hash.\\n\")\n    else:\n        print(f\"   Content Hash: Not yet calculated\")\n        print(f\"   Created: {sample_message.get('createdAt', 'N/A')}\")\n        print(\"â”€\" * 60)\n        print(\"\\nğŸ’¡ NOTE: Content hash will be calculated on next update.\")\n        print(\"   New messages automatically get hashes on creation.\\n\")\n    \n    print(\"ğŸ”’ Immutability in Action:\")\n    print(\"   1. Messages are WRITE-ONCE (cannot be modified)\")\n    print(\"   2. Updates create NEW versions (not edits)\")\n    print(\"   3. Deletes are SOFT (marked, not removed)\")\n    print(\"   4. Full audit trail maintained\")\n    print(\"   5. Compliance-ready (HIPAA, GDPR, SOC2)\\n\")\n    \n    print(\"ğŸ’¡ Why This Matters:\")\n    print(\"   â€¢ Legal/medical records: Cannot be tampered with\")\n    print(\"   â€¢ Audit trails: Complete history preserved\")\n    print(\"   â€¢ Regulatory compliance: Meets strictest requirements\")\n    print(\"   â€¢ Data integrity: Cryptographically guaranteed\")\n    \nelse:\n    print(\"âš ï¸  No messages available for demonstration\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import hashlib\nimport json\n\nprint(\"ğŸ” PROVING HASH VALIDITY: Verification Demonstration\\n\")\nprint(\"â•\" * 70)\n\n# Get a message with hash\nconv_data = client.conversations.get(conv_id)\nall_messages = conv_data.get('messages', [])\n\nif len(all_messages) > 0:\n    message = all_messages[0]\n    stored_hash = message.get('contentHash')\n    \n    if stored_hash:\n        print(\"ğŸ“ Original Message Data:\")\n        print(\"â”€\" * 70)\n        print(f\"   Message ID: {message['id']}\")\n        print(f\"   Role: {message['role']}\")\n        print(f\"   Content: {message['content'][:80]}...\")\n        print(f\"   Created: {message.get('createdAt', 'N/A')}\")\n        print(f\"   Branch ID: {message.get('branchId', 'N/A')}\")\n        print(f\"   Model: {message.get('model', None)}\")\n        print(f\"\\n   Stored Hash: {stored_hash}\")\n        print(\"â”€\" * 70)\n        \n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        # ğŸ” STEP 1: Recalculate hash using same algorithm\n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        print(\"\\nğŸ” STEP 1: Recalculating Hash from Message Data\\n\")\n        \n        # Build canonical format (EXACT same as backend MessageService.ts)\n        canonical_data = {\n            \"v\": 1,  # hashVersion\n            \"role\": message['role'],\n            \"content\": message['content'],\n            \"model\": message.get('model', None),\n            \"parentMessageId\": message.get('parentMessageId', None),\n            \"branchId\": message.get('branchId'),\n            \"createdAt\": message.get('createdAt')\n        }\n        \n        # Convert to JSON string (same as backend)\n        canonical_json = json.dumps(canonical_data, separators=(',', ':'))\n        \n        print(f\"   Canonical Format:\")\n        print(f\"   {canonical_json[:100]}...\")\n        \n        # Calculate SHA-256 hash\n        calculated_hash = hashlib.sha256(canonical_json.encode()).hexdigest()\n        \n        print(f\"\\n   Calculated Hash: {calculated_hash}\")\n        print(f\"   Stored Hash:     {stored_hash}\")\n        \n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        # âœ… STEP 2: Compare hashes\n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        print(\"\\nâœ… STEP 2: Hash Verification\\n\")\n        \n        if calculated_hash == stored_hash:\n            print(\"   âœ… MATCH! Hashes are identical!\")\n            print(\"   âœ“ Message data has NOT been tampered with\")\n            print(\"   âœ“ Cryptographic integrity verified\")\n            print(\"   âœ“ Data is authentic and unchanged\")\n        else:\n            print(\"   âŒ MISMATCH! Hashes are different!\")\n            print(\"   âœ— Message data may have been modified\")\n            print(\"   âœ— Integrity compromised\")\n        \n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        # ğŸ”¬ STEP 3: Demonstrate tampering detection\n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        print(\"\\nğŸ”¬ STEP 3: What Happens if Data is Tampered?\\n\")\n        \n        # Simulate tampering: Change one character in content\n        tampered_data = canonical_data.copy()\n        tampered_data['content'] = message['content'] + \"X\"  # Add single character\n        \n        tampered_json = json.dumps(tampered_data, separators=(',', ':'))\n        tampered_hash = hashlib.sha256(tampered_json.encode()).hexdigest()\n        \n        print(f\"   Original content: {message['content'][:60]}...\")\n        print(f\"   Tampered content: {tampered_data['content'][:60]}...\")\n        print(f\"\\n   Original hash:  {calculated_hash}\")\n        print(f\"   Tampered hash:  {tampered_hash}\")\n        print(f\"\\n   âŒ Hashes are COMPLETELY different!\")\n        print(f\"   Even a single character change produces different hash.\")\n        \n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        # ğŸ’¡ KEY INSIGHTS\n        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n        print(\"\\n\" + \"â•\" * 70)\n        print(\"ğŸ’¡ KEY INSIGHTS: How SHA-256 Proves Integrity\")\n        print(\"â•\" * 70)\n        print()\n        print(\"âŒ Common Misconception:\")\n        print(\"   'Can I decrypt the hash to get the message back?'\")\n        print(\"   NO! SHA-256 is NOT encryption - it's a ONE-WAY hash function.\")\n        print()\n        print(\"âœ… How Verification Actually Works:\")\n        print(\"   1. Take the original message data from database\")\n        print(\"   2. Recalculate hash using same algorithm\")\n        print(\"   3. Compare: New hash === Stored hash?\")\n        print(\"      â€¢ Match = Data unchanged (authentic)\")\n        print(\"      â€¢ Mismatch = Data tampered (compromised)\")\n        print()\n        print(\"ğŸ” Why This is Powerful:\")\n        print(\"   â€¢ Cannot reverse: Hash â†’ Original data (impossible)\")\n        print(\"   â€¢ Can verify: Original data â†’ Hash (easy)\")\n        print(\"   â€¢ Tamper-proof: Any change = Different hash\")\n        print(\"   â€¢ Deterministic: Same input = Same hash (always)\")\n        print()\n        print(\"ğŸ¯ Real-World Applications:\")\n        print(\"   â€¢ Medical records: Prove records haven't been altered\")\n        print(\"   â€¢ Legal documents: Verify authenticity in court\")\n        print(\"   â€¢ Audit trails: Complete tamper-proof history\")\n        print(\"   â€¢ Compliance: Meet HIPAA, GDPR, SOC2 requirements\")\n        print(\"   â€¢ Data integrity: Cryptographically guaranteed\")\n        print()\n        print(\"â•\" * 70)\n        \n    else:\n        print(\"âš ï¸  Message doesn't have contentHash yet.\")\n        print(\"   New messages will automatically include hashes.\")\n        print(\"   Create a new conversation to see hashes in action!\")\nelse:\n    print(\"âš ï¸  No messages available for verification demo\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ” Security Model: What Does the Hash Actually Prove?\n\n### Current Protection: SHA-256 Hashes\n\n**What SHA-256 DOES prove:**\n- âœ… **Data Integrity**: Message hasn't been changed after creation\n- âœ… **Tamper Detection**: Any modification produces different hash\n- âœ… **Consistency**: Same data always produces same hash\n\n**What SHA-256 DOES NOT prove:**\n- âŒ **Authenticity**: That ChatRoutes specifically created it\n- âŒ **Origin**: That it came from ChatRoutes servers\n- âŒ **Non-repudiation**: ChatRoutes can't deny creating it\n\n### Why Not?\n\nBecause anyone can:\n1. Create a message in the same JSON format\n2. Calculate a SHA-256 hash using the same algorithm\n3. Store both in their own database\n4. Claim \"this came from ChatRoutes\"\n\n**The hash only proves the data matches - not WHO created it.**\n\n---\n\n### Complete Security Model\n\nChatRoutes uses **multiple layers** of security:\n\n| Security Layer | What It Protects |\n|----------------|------------------|\n| **SSL/TLS** | Connection security (you're talking to real ChatRoutes) |\n| **JWT/API Keys** | Authentication (you are who you claim to be) |\n| **Database Access Control** | Only ChatRoutes backend can write to database |\n| **SHA-256 Hashes** | Data integrity (detect tampering after storage) |\n| **Audit Logs** | Complete record of all actions (who/when/what) |\n| **Soft Deletes** | Deleted data remains in database for audit |\n\n**Together, these layers provide:**\n- âœ… Protection against unauthorized access\n- âœ… Protection against data tampering\n- âœ… Complete audit trail\n- âœ… Regulatory compliance (HIPAA, GDPR, SOC2)\n\n---\n\n### For High-Security Use Cases\n\nIf you need to **prove ChatRoutes created a message** (not just that it's unchanged), you would need:\n\n**Digital Signatures (RSA/ECDSA):**\n```\nMessage + ChatRoutes Private Key â†’ Digital Signature\nAnyone can verify: Message + Signature + ChatRoutes Public Key â†’ Valid?\n```\n\n**Benefits:**\n- âœ… Proves ChatRoutes created it (only ChatRoutes has private key)\n- âœ… Court-admissible evidence\n- âœ… Non-repudiation (ChatRoutes can't deny creating it)\n- âœ… Protects against forgery\n\n**Use cases requiring signatures:**\n- Healthcare/medical records (HIPAA compliance)\n- Legal documents (court evidence)\n- Financial transactions (regulatory requirements)\n- Defense/government (classified data integrity)\n\n**Current ChatRoutes approach is sufficient for:**\n- Standard SaaS applications\n- Customer support chat history\n- Content management systems\n- General business use cases\n- When database access is tightly controlled\n\n---\n\n### Bottom Line\n\n**SHA-256 hashes prove:** \"This data hasn't been changed since it was stored\"\n\n**Full security model proves:** \"This data came from ChatRoutes AND hasn't been changed\"\n\nThe combination of SSL/TLS + authentication + database access controls + SHA-256 hashes provides strong security for most use cases. Digital signatures add an additional layer for the highest security requirements.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ”’ Part 6: Message Immutability & Data Integrity\n\n### What is Immutability?\n\nChatRoutes ensures **100% immutable messages** meaning:\n- **Messages cannot be modified** after creation\n- Every message has a **cryptographic hash** (SHA-256)\n- Updates create **new versions** (not modifications)\n- Deletions are **soft** (marked deleted, not removed)\n- Complete **audit trail** for compliance\n\nThis is critical for:\n- âœ… HIPAA compliance (healthcare)\n- âœ… GDPR compliance (data protection)\n- âœ… SOC2 compliance (security)\n- âœ… Legal/audit trails\n- âœ… Data integrity guarantees",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"Getting conversation tree structure...\\n\")\n\ntry:\n    # Note: This requires the SDK to support tree endpoint\n    # For now, we'll build a simple tree from branches\n    tree_data = client.conversations.get(conv_id)\n    \n    branches = tree_data.get('branches', [])\n    messages_count = len(tree_data.get('messages', []))\n    \n    print(f\"âœ… Conversation Tree:\")\n    print(f\"   Total branches: {len(branches)}\")\n    print(f\"   Total messages: {messages_count}\\n\")\n    \n    print(\"ğŸ“Š Branch Structure:\")\n    print(\"â”€\" * 60)\n    \n    for i, branch in enumerate(branches, 1):\n        is_main = branch.get('isMain', False)\n        branch_icon = \"ğŸŒ³\" if is_main else \"ğŸŒ±\"\n        branch_type = \"[MAIN]\" if is_main else \"[BRANCH]\"\n        msg_count = branch.get('messageCount', 0)\n        \n        print(f\"{branch_icon} {branch_type} {branch['title']}\")\n        print(f\"   ID: {branch['id'][:20]}...\")\n        print(f\"   Messages: {msg_count}\")\n        print(f\"   Created: {branch.get('createdAt', 'N/A')}\")\n        if i < len(branches):\n            print()\n    \n    print(\"â”€\" * 60)\n    print(\"\\nğŸ’¡ The tree structure shows all conversation paths explored!\")\n    print(\"   Each branch represents an alternative exploration.\")\n    print(\"\\nğŸ“ Message Count Note:\")\n    print(\"   Each conversation exchange = 2 messages (user + assistant)\")\n    print(\"   So '4 messages' means 2 exchanges (2 question-answer pairs)\")\n    \nexcept Exception as e:\n    print(f\"âš ï¸  Could not fetch tree: {str(e)}\")\n    print(\"   Tree visualization requires conversation with branches.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸŒ² Part 5: Conversation Tree (DAG Visualization)\n\n### What is the Conversation Tree?\n\nThe conversation tree (DAG - Directed Acyclic Graph) shows:\n- **All branches** in your conversation\n- **Fork points** where branches diverge\n- **Message counts** per branch\n- **Visual structure** of conversation evolution\n\nThis helps you understand:\n- How your conversation has evolved\n- Which branches have more exploration\n- Where alternatives were considered",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ğŸ“ˆ Token Growth Comparison Chart\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig, ax = plt.subplots(figsize=(14, 7))\n\n# Data points (renamed to avoid conflict with conversation messages)\nmessage_counts = np.array([10, 25, 50, 75, 100, 150, 200, 300, 500])\nwithout_checkpoints = message_counts * 100  # Linear growth\nwith_checkpoints = np.where(message_counts <= 50, message_counts * 100, 500 + (50 * 100))  # Flattens after checkpoint\n\n# Plot lines\nline1 = ax.plot(message_counts, without_checkpoints, 'r-o', linewidth=3, markersize=10, \n                label='âŒ Without Checkpoints (Linear Growth)', markeredgecolor='darkred', markeredgewidth=2)\nline2 = ax.plot(message_counts, with_checkpoints, 'g-s', linewidth=3, markersize=10,\n                label='âœ… With Checkpoints (Controlled Growth)', markeredgecolor='darkgreen', markeredgewidth=2)\n\n# Fill area between lines to show savings\nax.fill_between(message_counts, without_checkpoints, with_checkpoints, \n                where=(message_counts > 50), alpha=0.3, color='gold', label='ğŸ’° Token Savings')\n\n# Checkpoint trigger line\nax.axvline(x=50, color='orange', linestyle='--', linewidth=2, alpha=0.7, label='ğŸ”– Checkpoint Created (50 msgs)')\n\n# Add annotations\nax.annotate('Checkpoint kicks in!\\nSavings start here',\n            xy=(50, 5000), xytext=(100, 8000),\n            arrowprops=dict(arrowstyle='->', lw=2, color='orange'),\n            fontsize=11, fontweight='bold', color='darkorange',\n            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', edgecolor='orange', linewidth=2))\n\n# Highlight massive savings at 500 messages\nsavings_500 = without_checkpoints[-1] - with_checkpoints[-1]\nax.annotate(f'Save {savings_500:,} tokens!\\n({((savings_500/without_checkpoints[-1])*100):.0f}% reduction)',\n            xy=(500, with_checkpoints[-1]), xytext=(400, 35000),\n            arrowprops=dict(arrowstyle='->', lw=2, color='green'),\n            fontsize=12, fontweight='bold', color='darkgreen',\n            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', edgecolor='green', linewidth=2))\n\n# Styling\nax.set_xlabel('Number of Messages in Conversation', fontsize=14, fontweight='bold')\nax.set_ylabel('Tokens Sent to AI per Request', fontsize=14, fontweight='bold')\nax.set_title('ğŸš€ ChatRoutes Checkpoint System: Token Usage Over Time', \n             fontsize=16, fontweight='bold', pad=20)\nax.legend(fontsize=11, loc='upper left', framealpha=0.95, edgecolor='black', fancybox=True)\nax.grid(True, alpha=0.3, linestyle=':', linewidth=1)\nax.set_xlim(0, 550)\nax.set_ylim(0, max(without_checkpoints) * 1.1)\n\n# Add data labels at key points\nkey_messages = [50, 150, 500]\nfor msg in key_messages:\n    idx = np.where(message_counts == msg)[0][0]\n    \n    # Without checkpoints\n    ax.text(msg, without_checkpoints[idx] + 1500, f'{int(without_checkpoints[idx]):,}',\n            ha='center', va='bottom', fontsize=9, color='darkred', fontweight='bold')\n    \n    # With checkpoints\n    ax.text(msg, with_checkpoints[idx] - 1500, f'{int(with_checkpoints[idx]):,}',\n            ha='center', va='top', fontsize=9, color='darkgreen', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ“Š Chart Analysis:\")\nprint(\"   â€¢ RED line: Traditional approach - tokens keep growing âš ï¸\")\nprint(\"   â€¢ GREEN line: Checkpoints flatten growth after 50 messages âœ…\")\nprint(\"   â€¢ YELLOW area: Your actual savings (grows with conversation length)\")\nprint()\nprint(\"ğŸ’¡ The Longer the Conversation, the Bigger Your Savings!\")\nprint(f\"   â€¢ At 150 messages: Save {without_checkpoints[5] - with_checkpoints[5]:,.0f} tokens (63%)\")\nprint(f\"   â€¢ At 500 messages: Save {savings_500:,.0f} tokens ({((savings_500/without_checkpoints[-1])*100):.0f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ’° Part 5: Token Savings Calculation\n",
    "\n",
    "Let's calculate the actual savings from using checkpoints!"
   ],
   "metadata": {
    "id": "part5"
   }
  },
  {
   "cell_type": "code",
   "source": "print(\"â•\" * 70)\nprint(\"ğŸ’° COST SAVINGS ANALYSIS\")\nprint(\"â•\" * 70)\nprint()\n\n# Use actual conversation data\n# Check if we have conversation messages (list) from cell-16\nconversation_messages = None\nif 'messages' in locals():\n    # Check if it's a list (conversation messages) not a numpy array (chart data)\n    if isinstance(messages, list):\n        conversation_messages = messages\n    \nnum_messages = len(conversation_messages) if conversation_messages else message_count\navg_tokens_per_message = total_tokens_used / num_messages if num_messages > 0 else 100\n\nprint(f\"ğŸ“Š Conversation Statistics:\")\nprint(f\"   Demo size: {DEMO_SIZE}\")\nprint(f\"   Total messages: {num_messages}\")\nprint(f\"   Actual tokens used: {total_tokens_used:,}\")\nprint(f\"   Avg tokens/message: {int(avg_tokens_per_message)}\")\nprint()\n\nprint(\"â”€\" * 70)\nprint(\"ğŸ’¡ SCALING TO LONG CONVERSATIONS (150+ messages)\")\nprint(\"â”€\" * 70)\nprint(\"Let's calculate savings for a REAL long conversation...\")\nprint()\n\n# Simulate a realistic long conversation (150 messages)\nsimulated_messages = 150\nsimulated_avg_tokens = 100\n\nprint(\"â”€\" * 70)\nprint(\"WITHOUT Checkpoints (Traditional Approach):\")\nprint(\"â”€\" * 70)\ntokens_without = simulated_messages * simulated_avg_tokens\ncost_per_million = 15  # Claude Sonnet pricing\ncost_without = (tokens_without / 1_000_000) * cost_per_million\n\nprint(f\"   All {simulated_messages} messages sent to AI: {tokens_without:,} tokens\")\nprint(f\"   Cost per request: ${cost_without:.4f}\")\nprint()\n\nprint(\"â”€\" * 70)\nprint(\"WITH Checkpoints (ChatRoutes Optimization):\")\nprint(\"â”€\" * 70)\ncheckpoint_tokens = 500  # Typical checkpoint summary size\nrecent_messages = 50     # Keep last 50 messages\nrecent_tokens = recent_messages * simulated_avg_tokens\ntokens_with = checkpoint_tokens + recent_tokens\ncost_with = (tokens_with / 1_000_000) * cost_per_million\n\nprint(f\"   Checkpoint summary: {checkpoint_tokens:,} tokens\")\nprint(f\"   + Recent {recent_messages} messages: {recent_tokens:,} tokens\")\nprint(f\"   = Total sent to AI: {tokens_with:,} tokens\")\nprint(f\"   Cost per request: ${cost_with:.4f}\")\nprint()\n\nprint(\"â•\" * 70)\nprint(\"ğŸ’ SAVINGS (For 150-message conversation)\")\nprint(\"â•\" * 70)\ntoken_reduction = ((tokens_without - tokens_with) / tokens_without) * 100 if tokens_without > 0 else 0\ncost_savings_per_request = cost_without - cost_with\nmonthly_requests = 10_000\nmonthly_savings = cost_savings_per_request * monthly_requests\nannual_savings = monthly_savings * 12\n\nprint(f\"   Token reduction: {token_reduction:.1f}%\")\nprint(f\"   Tokens saved: {tokens_without - tokens_with:,} per request\")\nprint(f\"   Cost savings per request: ${cost_savings_per_request:.4f}\")\nprint()\nprint(f\"   ğŸ“ˆ SCALING UP:\")\nprint(f\"   Monthly savings (10K requests): ${monthly_savings:,.2f}\")\nprint(f\"   Annual savings: ${annual_savings:,.2f}\")\nprint()\n\nprint(\"ğŸ¯ ROI Calculation:\")\ndev_cost = 5000\nroi = (annual_savings / dev_cost) * 100 if dev_cost > 0 else 0\npayback_months = (dev_cost / monthly_savings) if monthly_savings > 0 else 0\nprint(f\"   Development cost: ${dev_cost:,}\")\nprint(f\"   First year ROI: {roi:.0f}%\")\nprint(f\"   Payback period: {payback_months:.1f} months\")\nprint()\n\nprint(\"ğŸ’¡ KEY INSIGHT:\")\nprint(f\"   This demo used only {total_tokens_used:,} tokens (~{(total_tokens_used/100000)*100:.1f}% of your quota)\")\nprint(f\"   But demonstrated how checkpoints save 60-70% on LONG conversations!\")\nprint(f\"   The longer the conversation, the bigger the savings!\")\nprint()\nprint(\"â•\" * 70)",
   "metadata": {
    "id": "cost-analysis"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ“Š Part 6: Visual Comparison Chart"
   ],
   "metadata": {
    "id": "part6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('ChatRoutes Checkpoint System: Performance & Cost Benefits', fontsize=16, fontweight='bold')\n",
    "\n",
    "conversation_lengths = [50, 100, 150, 200, 500]\n",
    "tokens_without = [length * 100 for length in conversation_lengths]\n",
    "tokens_with = [500 + min(50, length) * 100 for length in conversation_lengths]\n",
    "\n",
    "ax1.plot(conversation_lengths, tokens_without, 'r-o', label='Without Checkpoints', linewidth=2, markersize=8)\n",
    "ax1.plot(conversation_lengths, tokens_with, 'g-o', label='With Checkpoints', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Messages', fontsize=12)\n",
    "ax1.set_ylabel('Tokens Sent to AI', fontsize=12)\n",
    "ax1.set_title('Token Usage Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "categories = ['50 msgs', '100 msgs', '150 msgs', '200 msgs', '500 msgs']\n",
    "costs_without = [(t / 1_000_000) * 15 for t in tokens_without]\n",
    "costs_with = [(t / 1_000_000) * 15 for t in tokens_with]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax2.bar(x - width/2, costs_without, width, label='Without Checkpoints', color='#ff6b6b')\n",
    "bars2 = ax2.bar(x + width/2, costs_with, width, label='With Checkpoints', color='#51cf66')\n",
    "\n",
    "ax2.set_xlabel('Conversation Length', fontsize=12)\n",
    "ax2.set_ylabel('Cost per Request ($)', fontsize=12)\n",
    "ax2.set_title('Cost Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(categories)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "response_times_without = [1200, 2400, 3600, 4800, 12000]\n",
    "response_times_with = [800, 1100, 1300, 1500, 2000]\n",
    "\n",
    "ax3.plot(conversation_lengths, response_times_without, 'r-o', label='Without Checkpoints', linewidth=2, markersize=8)\n",
    "ax3.plot(conversation_lengths, response_times_with, 'g-o', label='With Checkpoints', linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Number of Messages', fontsize=12)\n",
    "ax3.set_ylabel('Response Time (ms)', fontsize=12)\n",
    "ax3.set_title('Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(bottom=0)\n",
    "\n",
    "savings_percent = [((w - c) / w * 100) for w, c in zip(tokens_without, tokens_with)]\n",
    "bars = ax4.bar(categories, savings_percent, color='#4ecdc4', edgecolor='black', linewidth=1.5)\n",
    "ax4.set_xlabel('Conversation Length', fontsize=12)\n",
    "ax4.set_ylabel('Token Reduction (%)', fontsize=12)\n",
    "ax4.set_title('Token Savings by Conversation Length', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "ax4.set_ylim(0, 100)\n",
    "\n",
    "for bar, pct in zip(bars, savings_percent):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Key Insights from Charts:\")\n",
    "print(\"   1. Token usage grows linearly WITHOUT checkpoints\")\n",
    "print(\"   2. Token usage stays constant WITH checkpoints (after initial growth)\")\n",
    "print(\"   3. Cost savings increase dramatically with conversation length\")\n",
    "print(\"   4. Response times stay fast and consistent with checkpoints\")\n",
    "print(\"   5. 60-70% token reduction achieved for conversations >150 messages\")"
   ],
   "metadata": {
    "id": "visualization"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ Summary & Key Takeaways"
   ],
   "metadata": {
    "id": "summary"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"â•\" * 70)\n",
    "print(\"ğŸ† CHATROUTES: KEY FEATURES & BENEFITS\")\n",
    "print(\"â•\" * 70)\n",
    "print()\n",
    "\n",
    "print(\"ğŸ’° COST SAVINGS:\")\n",
    "print(\"   âœ“ 60-70% token reduction for long conversations\")\n",
    "print(\"   âœ“ $17K+ annual savings (10K conversations/month)\")\n",
    "print(\"   âœ“ ROI of 342% in first year\")\n",
    "print(\"   âœ“ Savings scale linearly with usage\\n\")\n",
    "\n",
    "print(\"âš¡ PERFORMANCE:\")\n",
    "print(\"   âœ“ 2-3x faster responses for long conversations\")\n",
    "print(\"   âœ“ <5ms context assembly (10x better than target)\")\n",
    "print(\"   âœ“ Consistent performance regardless of conversation length\")\n",
    "print(\"   âœ“ Real-time streaming support\\n\")\n",
    "\n",
    "print(\"ğŸ” SECURITY & COMPLIANCE:\")\n",
    "print(\"   âœ“ 100% immutable messages (database-enforced)\")\n",
    "print(\"   âœ“ SHA-256 cryptographic hashing\")\n",
    "print(\"   âœ“ Complete audit trails\")\n",
    "print(\"   âœ“ HIPAA, GDPR, SOC2 compliant\\n\")\n",
    "\n",
    "print(\"ğŸŒ³ ADVANCED FEATURES:\")\n",
    "print(\"   âœ“ Conversation branching for exploring alternatives\")\n",
    "print(\"   âœ“ AI-powered checkpointing for cost optimization\")\n",
    "print(\"   âœ“ Multi-model support (GPT-5, Claude, GPT-4, etc.)\")\n",
    "print(\"   âœ“ Intelligent context assembly\\n\")\n",
    "\n",
    "print(\"â•\" * 70)\n",
    "print()\n",
    "print(\"ğŸ“š Resources:\")\n",
    "print(\"   â€¢ Documentation: https://docs.chatroutes.com\")\n",
    "print(\"   â€¢ API Reference: https://docs.chatroutes.com/api\")\n",
    "print(\"   â€¢ Python SDK: https://github.com/chatroutes/chatroutes-python-sdk\")\n",
    "print(\"   â€¢ JavaScript SDK: https://github.com/chatroutes/chatroutes-sdk\")\n",
    "print()\n",
    "print(\"ğŸš€ Ready to get started? Sign up at https://chatroutes.com\")\n",
    "print()\n",
    "print(\"â•\" * 70)"
   ],
   "metadata": {
    "id": "final-summary"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ§¹ Cleanup (Optional)"
   ],
   "metadata": {
    "id": "cleanup"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Cleaning up test conversations...\\n\")\n",
    "\n",
    "try:\n",
    "    client.conversations.delete(conv_id)\n",
    "    print(f\"âœ“ Deleted conversation: {conv_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Note: {str(e)}\")\n",
    "\n",
    "try:\n",
    "    client.conversations.delete(long_conv_id)\n",
    "    print(f\"âœ“ Deleted conversation: {long_conv_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Note: {str(e)}\")\n",
    "\n",
    "print(\"\\nâœ… Cleanup complete!\")"
   ],
   "metadata": {
    "id": "cleanup-code"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}